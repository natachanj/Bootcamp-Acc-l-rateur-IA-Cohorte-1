job_title,company_name,location,work_mode,experience_level,salary_min,salary_max,avg_salary,tech_stack_str,job_description,job_url
Machine Learning Engineer Intern,Moloco,"London,  England,  United Kingdom",On-site,Junior,,,,"Go, Kubernetes, Machine Learning, TensorFlow","About Moloco: Moloco builds some of the most powerful AI advertising solutions in the world. Our name—short for ""machine learning company""—reflects our core mission: democratizing access to the advanced AI that has historically been reserved for tech giants. Led by machine learning pioneers who built some of the most successful ad systems at Google, including YouTube's monetization engine and key search advertising technologies, we're transforming how businesses grow and compete in the digital economy. Built with AI from day one, Moloco’s planet-scale machine learning platform powers a suite of solutions for advertising growth and monetization. Moloco Ads is an AI-powered platform that delivers real business outcomes for mobile app marketers through performance-based user acquisition. Moloco Commerce Media and Streaming Monetization solutions enable retailers, marketplaces, and streaming platforms to build revenue-generating ad businesses that balance user experience and advertiser performance. Moloco is headquartered in Silicon Valley, with offices in Seattle, New York, San Francisco, Seoul, Beijing, Singapore, Bangalore, Gurgaon, Tokyo, Shanghai, London, Tel Aviv, and Berlin. Moloco is a truly rewarding place to work and in an exciting period of growth, which you could be a part of. Join us today and apply now! The Impact You’ll Be Contributing to Moloco: We are an engineering company founded by engineers. We understand the value of a strong engineering team and strive to hire only the best engineering interns. We are seeking exceptional Machine Learning interns to join us in building a state-of-the-art machine learning system. Moloco’s programmatic advertising engine is powered by custom deep neural network models that handle 1M+ QPS at 7 ms prediction latencies. As an intern, you can expect to be a full member of the team you join and will be treated as a junior engineer, with the same expectations, project opportunities and responsibilities. Some examples of past intern projects are: Conducting experiments on state-of-the-art machine learning models using Tensorflow for real world, large scale problems. Constructing and enhancing data pipelines for model training and serving using Google cloud products such as Apache Beam/Dataflow, BigQuery, and BigTable. Building machine learning productivity tools (e.g. model quality measurement), deploy them in Kubernetes, and help model engineers adopt them. Minimum Qualifications: Able and willing to work from our London, England office. Must be able to work full-time (40 hours per week) for 12-weeks during the summer of 2026 (May - September). Currently enrolled in a Bachelor's, Master’s or PhD program in Computer Science, or a related technical field. Candidates pursuing a Bachelor's or Master's degree must be graduating and obtaining the degree by June of 2027. Preferred Qualifications: Strong background in data structures and algorithms. Strong coding and problem solving skills. Familiar with distributed systems and/or databases Fluent with at least one programming language Moloco Thrive: Benefits and Well-Being: We take care of you and create the conditions for you to do the best work of your career. We offer innovative benefits that empower our employees to take care of themselves and their families so they can do the best work of their lives. Moloco Values: Lead with Humility: Everyone’s voice is respected, valued, and heard. With humility, we become more open and accessible to each other. We win, lose, and learn together. Accountability and feedback are essential to our success. Uncapped Growth Mindset: We see all situations as opportunities to learn, grow, and improve as individuals and as an organization. We seek diverse perspectives, encourage curiosity, and promote experimentation to push the boundaries of what’s possible. Create Real Value: We pursue the most impactful opportunities with rigor and integrity. We take intelligent risks and make disciplined trade-offs to maintain deep focus. We help our customers win by delivering durable value. Go Further Together: We’re one team working towards one mission and vision. We collaborate proactively and inclusively, involving the right people at the right time and in the right way. We strive to create a more equitable workplace. We won’t let each other fail. Additional Resources: Moloco Company Blog Moloco Leadership Moloco Newsroom Equal Opportunity: Creating a diverse workforce and a culture of inclusion and belonging is core to our existence. To reach our goals, diversity of talent and thought is a critical component of how we operate as an organization. Our workforce is our superpower, and we know that fostering a culture of inclusion, authenticity, and belonging gives us the greatest opportunity to achieve our vision to become the scaling engine for the Internet economy. Moloco is an equal opportunity employer. We highly value diversity in our current and future employees and do not discriminate (inclu",https://aijobs.ai/job/machine-learning-engineer-intern-8
AI Software Engineer,Anaplan,"Manchester,  United Kingdom",Hybrid,Senior,,,,"Python, CI/CD, React, Java, Kafka","At Anaplan, we are a team of innovators focused on optimizing business decision-making through our leading AI-infused scenario planning and analysis platform so our customers can outpace their competition and the market. What unites Anaplanners across teams and geographies is our collective commitment to our customers’ success and to our Winning Culture. Our customers rank among the who’s who in the Fortune 50. Coca-Cola, LinkedIn, Adobe, LVMH and Bayer are just a few of the 2,400+ global companies who rely on our best-in-class platform. Our Winning Culture is the engine that drives our teams of innovators. We champion diversity of thought and ideas, we behave like leaders regardless of title, we are committed to achieving ambitious goals, and we love celebrating our wins – big and small. Supported by operating principles of being strategy-led, values -based and disciplined in execution, you’ll be inspired, connected, developed and rewarded here. Everything that makes you unique is welcome; join us and let’s build what’s next - together! Team Description As part of the Platform & AI Enablement team under GPTO Engineering, you’ll report to the Sr. Director Engineering API. This team is accountable for shaping enterprise data architecture, enabling high-performance AI-driven workloads, and acting as a technical bridge between engineering and architecture. This is a hands-on role for a deeply experienced engineer who thrives on solving complex problems and scaling robust platforms. Your Impact Influence the design and implementation of platform capabilities for data processing, AI enablement, and developer acceleration across batch, streaming, and real-time systems. Collaborate with the architecture function to represent engineering needs and help translate architectural direction into practical implementation patterns. Guide teams in integrating AI/ML capabilities—including prompt-based LLM use cases, model inference, and feature pipelines—into scalable platform services. Bring a product mindset to platform engineering, ensuring solutions are aligned with customer and business goals. Provide thought leadership across the fullstack (React, Java, Python), promoting clean, efficient, and maintainable code. Identify and drive opportunities for innovation—whether in development tooling, performance optimization, or new platform features. Act as a mentor to engineers across teams, elevating technical standards through code review, design input, and informal leadership. Participate in incident retrospectives, technical spike planning, and future-looking strategy discussions. Help teams balance speed and sustainability—delivering under tight deadlines without compromising quality. Your Qualifications Proven software engineering experience, ideally in platform, infrastructure, or data-centric product development. Expertise in Apache Kafka, Apache Flink, and/or Apache Pulsar. Deep understanding of event-driven architectures, data lakes, and streaming pipelines. Strong experience integrating AI/ML models into production systems, including prompt engineering for LLMs. Polyglot development capability, with hands-on experience in Java, Python, and modern frontend frameworks such as React. Comfort working in cloud-agnostic and hybrid environments. Familiar with CI/CD pipelines, GitOps practices, and releasing at speed. Strong communication skills—both technical and interpersonal—with the ability to influence without authority. Experience working within or across globally distributed teams. Preferred Skills Help define the future of a data platform at scale Work on cutting-edge AI/ML enablement initiatives Collaborate with high-caliber teams across data, engineering, and product Influence long-term technology strategy in a high-growth environment Our Commitment to Diversity, Equity, Inclusion and Belonging (DEIB) We believe attracting and retaining the best talent and fostering an inclusive culture strengthens our business. DEIB improves our workforce, enhances trust with our partners and customers, and drives business success. Build your career in a place where diversity, equity, inclusion and belonging aren’t just words on paper – this is what drives our innovation, it’s how we connect, and it contributes to what makes us a market leader. We believe in a hiring and working environment where all people are respected and valued, regardless of gender identity or expression, sexual orientation, religion, ethnicity, age, neurodiversity, disability status, citizenship, or any other aspect which makes people unique. We hire you for who you are, and we want you to bring your authentic self to work every day! We will ensure that individuals with disabilities are provided reasonable accommodation to participate in the job application or interview process, perform essential job functions, and receive equitable benefits and all privileges of employment. Please contact us to request accommodation. Fraud Recruitment Disclaimer It has co",https://aijobs.ai/job/ai-software-engineer-2
"Senior AI Engineer, AI Labs",NPR,"Washington,  District of Columbia,  United States",Hybrid,Senior,0.0,186000.0,93000.0,"AWS, Python, CI/CD, GCP, Machine Learning","OVERVIEW A thriving, mission-driven multimedia organization, NPR produces award-winning news, information, and music programming in partnership with hundreds of independent public radio stations across the nation. The NPR audience values information, creativity, curiosity, and social responsibility – and our employees do too. We are innovators and leaders in diverse fields, from journalism and digital media to IT and development. Every day, our employees and member stations touch the lives of millions worldwide. Across our organization, we’re building a workplace where collaboration is essential, diverse voices are heard, and inclusion is the key to our success. We are committed to doing the right thing in our journalism and in every role at NPR . This means that integrity, adherence to our ethical standards, and compliance with legal obligations are fundamental responsibilities for every employee at NPR. Intro to Position The Senior AI Engineer, AI Labs, is a foundational role in building NPR's first Generative AI (GAI)-focused product development team. Reporting to the VP of AI Labs, this engineer will be responsible for the technical development and implementation of generative AI solutions. The core mission is to engineer systems that leverage GAI to enhance the quality and actionability of our content metadata, thereby directly supporting the organization's goals of improving content personalization and increasing editorial efficiency. This role involves hands-on work in integrating AI products into core NPR systems, ensuring solutions are scalable, align with ethical guidelines, and are built upon industry best practices. This is a critical opportunity to shape NPR's technical AI adoption and build a new, innovative function. Responsibilities Engineering & Implementation: Design, develop, and deploy scalable Generative AI (GAI) solutions, focusing on enhancing content metadata quality and actionability to meet organizational objectives. Architecture & Technical Best Practices: Establish and champion technical best practices for Generative AI systems, including MLOps, RAG architectures, prompt engineering, and model evaluation, ensuring high-quality, maintainable code. Cross-functional Development: Collaborate closely with Product Managers, data scientists, software and infrastructure engineers, and relevant subject matter experts to translate product requirements and roadmaps into robust, production-ready AI systems. System Optimization & Performance: Implement data-driven methods, A/B testing, and performance monitoring to optimize the efficiency, scalability, and impact of AI models and pipelines. Technical Communication: Clearly articulate technical architectures, development progress, and engineering challenges to product and non-technical stakeholders. Responsible AI: Integrate ethical AI principles and compliance standards directly into the design and implementation of all AI products, in alignment with company policies. Technology Scouting: Research and evaluate emerging AI technologies, frameworks, and industry trends to drive continuous technical innovation within the AI Labs. The above duties and responsibilities are not an exhaustive list of required responsibilities, duties and skills. Other duties may be assigned, and this job description is subject to change at any time. Minimum Qualifications 5+ years of professional experience in software development, data science, or machine learning engineering, with a focus on building and deploying production systems. 2+ years of hands-on experience working with generative AI, machine learning, or data products. Expert proficiency in Python and experience creating functional prototypes to validate technical feasibility and user flows. Demonstrable understanding and experience building products that leverage Large Language Models, RAG architectures, prompting, function calling, retrieval, vector databases, embeddings, fine-tuning, and model evaluation. Familiarity with building and integrating MCP servers and agentic workflows Background in creating QA systems for AI processes and development Excellent communication skills and the ability to clearly articulate technical architectures and challenges to product and non-technical stakeholders. A collaborative and respectful approach to work and an ability to adapt quickly to change. A deep commitment to the mission of NPR and to the responsible implementation of Generative AI technologies. Preferred Qualifications Experience designing and building highly scalable, production-grade AI/ML pipelines and services. Proficiency with cloud platforms, particularly AWS and Google Cloud Platform (GCP) and MLOps tools, particularly MLFlow and Vertex AI. Experience with DevOps practices, including CI/CD and enterprise infrastructure-as-code. Experience working in media organizations and an understanding of media delivery systems. Work Location & Requirements Hybrid Permitted: This is a hybrid permitted role. Some ",https://aijobs.ai/job/senior-ai-engineer-ai-labs
AI/ML Engineer / Solution Designer – Toronto - Hybrid,Capco,Canada - Toronto,Hybrid,Senior,,,,"TensorFlow, PyTorch","AI/ML Engineer / Solution Designer – Toronto - Hybrid ** this is for upcoming project work within the banking & capital market sectors ** Capco – The Future. Now. Capco is a distinctly and positively different place to work. Much more than consultants, we are active participants in the global financial services industry. Our passionate business and technology professionals enjoy a unique environment where they are actively encouraged to apply intellect, innovation, experience and teamwork. We ware dedicated to fully supporting our world class clients as they respond to challenges and opportunities in: Banking & Payments, Capital Markets, Insurance, Wealth & Asset Management and Energy. Experience Capco for yourself at capco.com . Let’s Talk About You You want to Own Your Career. You’re serious about rising as far and as fast as your work and achievements can take you. And you’re ready to write the next chapter of your career story: a challenging and rewarding role. Let’s Get Down to Business Capco is looking for talented, innovative and creative people to join our incredible and growing Team focused on our financial services clients. We are looking for experienced talent exceptional domain expertise who can work directly with our clients on mission-critical projects. About the Role Responsibilities Design, prototype, and refine models (e.g. fine tuning, prompt design, agent logic). R&D on architecture, embeddings, memory, safety/guardrails. Show Us What You’ve Got 5+ years related experience. Deep understanding of LLMs, transformers, embeddings, retrieval-augmented generation (RAG). Experience with frameworks: PyTorch, TensorFlow, JAX. Knowledge of prompt engineering, chain-of-thought, agent frameworks (e.g. LangChain, LlamaIndex, etc.). Familiarity with data pipelines, vector DBs, embedding services (FAISS, Pinecone, etc.). Skills in evaluation, benchmarking, safety, adversarial testing Analytical mind and problem-solving aptitude. Strong organizational skills. BSc/BA in Computer Science, Engineering, or a related field. Professional experience is important. But it’s paramount you share our belief in disruptive innovation that puts clients ahead in a tough market. From day one, your key mission will be to perceive new and better ways of doing things to give your clients an advantage. Now Take the Next Step We have: Access to industry-focused talent globally Ability to leverage best-in-class innovative products and solutions for complex architecture and large-scale transformation Extended global geographic market reach Ability to capitalize on our client footprint and deep domain expertise within financial services and energy Capco is an equal opportunity employer. We evaluate qualified applicants without regard to race, colour, religion, sex, sexual orientation, gender identity, marital status, genetic information, national origin, disability, veteran status, and other protected characteristics. For more information about Capco, visit www.Capco.com . We have been informed of several recruitment scams targeting the public. We strongly advise you to verify identities before engaging in recruitment related communication. All official Capco communication will be conducted via a Capco recruiter.",https://aijobs.ai/job/aiml-engineer-solution-designer-toronto-hybrid
Machine Learning Engineer,Speechmatics,"Cambridge,  England,  United Kingdom",Hybrid,Senior,2000.0,3000.0,2500.0,"Go, Machine Learning","Speechmatics is a cutting-edge applied AI Research company that is breaking down cultural barriers by building diverse and inclusive speech technology. We are looking for an experienced Machine Learning Engineer who can help us advance our automatic speech recognition (ASR) engines for Flow, our new Conversational AI companion and create interactive voice interfaces of the future that ‘Understand Every Voice’. We are betting big on scaling models, so you will be working with millions of hours of audio and billion parameter models which train across dozens of GPUs. It’s all about finding bottlenecks across our 50+ languages. Our main research focuses are large-scale self-supervised learning, building state-of-the-art speech pipelines and breaking ground on our own emotive text-to-speech (TTS) models. What you'll be doing Working with a diverse group of engineers across Speechmatics. Scaling self-supervised learning models across hundreds of GPUs in the cloud. Experimenting with distillation or quantisation to speed up our models at runtime. Comparing compute efficiencies of architectures such as a transformer and the impact on WER. Developing new, state-of-the-art AI features, from training models, all the way to shipping it to production. Advancing end-to-end speech models and researching new approaches to TTS. We aim to get you onboarded and started on projects in your first few days. In addition, having a very collaborative culture, you will often be pair programming with a colleague on streamlining our production ML pipelines, reviewing other folks’ code and suggesting new ways to tackle a tough real time factor (RTF) optimisation problem, as well as brainstorming novel approaches for analysing model predictions with the team. You’ll want to join our team if you Ambitious Engineers keen to work on bleeding-edge speech recognition and representational learning. Experience owning areas of code, seeking alignment rather than guidance. Proven-track record of delivering results, moving fast and keeping things simple. Someone who loves working in collaborative and diverse teams. Has a growth mindset and loves to develop oneself and others. Enjoys solving challenging problems and optimising a stack of unfamiliar code. We encourage you to apply even if you do not feel you match all of the requirements exactly. The list of requirements is intended to show the kinds of experience and qualities we’re looking for, but it is not exhaustive. If you are interested in the role, the team, and our mission, we would love to consider your application. We are always open to conversations and look forward to hearing from you. Who we are: Speechmatics is the leading expert in Speech Intelligence, and uses AI and Machine Learning to unlock business value in human speech worldwide. We work with an amazing mix of global companies, and our technology can integrate into our customers stack irrespective of their industry or use case – making it the go-to solution to harness useful information from speech. Joining us means working with some of the smartest minds around the world, focused on cutting-edge projects and deploying the latest techniques to disrupt the market. We believe in putting people first; we’ll do all we can to help you develop your skills and give you the tools you need to thrive. Our Focus Fridays give you an undisturbed day of focus, offset with Together Tuesdays when we have our team meetings, so you've always got the right balance. We have structured a hybrid approach that includes 2-3 designated office days each week. This arrangement ensures that while we embrace the advantages of remote work, we also maintain the vital connection and synergy that only in-person interactions can foster. This is only the beginning; we’re looking for amazing people like you to continue our journey… What we can offer you: No matter what stage of your career you’re at - from paid internships and first-job opportunities through to management and senior positions - we’ll support you with the training and development needed to reach your career aspirations with us. There really is no shortage of opportunities here for you to get involved and collaborate with those around you to deliver your best work. We offer incredibly flexible working, regular company lunches, and birthday celebrations. But that’s not all. We’ve spoken to our teams to find out what they want. From Private Medical, and Dental for you and your family, through to global working opportunities, a generous holiday allowance and pension/401K matching, we want to make sure our employees and their families are looked after. Every employee will receive a working from home allowance for tech or home office equipment (on top of your choice of laptop and accessories of course). Our approach to parental leave is designed to support employees globally. While this varies by geo, we have support in place for parents (including adoption assistance and reproductive health services) ",https://aijobs.ai/job/machine-learning-engineer-2462
Sr. Machine Learning Engineer,PitchBook Data,"New York,  United States",Remote,Senior,0.0,240000.0,120000.0,"Scikit-learn, Python, Java, Docker, Kubernetes, Kafka, Machine Learning, TensorFlow, PyTorch","At PitchBook, a Morningstar company, we are always looking forward. We continue to innovate, evolve, and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy, and fun that reverberates throughout the company. Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast, and do it all over again in the pursuit of excellence. If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you. About the Role: As a member of the Product and Engineering team at PitchBook, you will be part of a team of big thinkers, innovators, and problem solvers who strive to deepen the positive impact we have on our customers and our company every day. We value curiosity and the drive to find better ways of doing things. We thrive on customer empathy, which remains our focus when creating excellent customer experiences through product innovation. We know that greatness is achieved through collaboration and diverse points of view, so we work closely with partners around the globe. As a team, we assume positive intent in each other’s words and actions, value constructive discussions, and foster a respectful working environment built on integrity, growth, and business value. We invest heavily in our people, who are eager to learn and constantly improve. Join our team and grow with us! As a Senior Machine Learning Engineer (MLE) on the AI & ML (Insights) team, you will play a critical role in delivering AI-powered features that extract meaningful insights from PitchBook’s wealth of structured and unstructured data including reports, news, and other textual content. This role requires deep technical expertise in advanced data analytics and machine learning, as well as a hands-on approach to designing, building, and optimizing ML solutions that power user-facing features on the PitchBook Platform. You will be deeply involved in the end-to-end development and operationalization of ML models, including their architecture, training, deployment, and ongoing maintenance. Your focus will span across natural language processing (NLP), generative AI (GenAI), large language models (LLMs), and scalable data systems. You will be expected to tackle complex technical challenges, contribute to architectural decisions, and collaborate closely with other engineers, data scientists, and product managers to ensure that your work aligns with business goals and AI/ML strategy. Your contributions will help unlock unique value for PitchBook customers by improving the speed, discoverability, quality, and quantity of insights available on the platform. This includes developing models that can infer meaning and structure from millions of discrete data sources, and applying ML to enrich our datasets with predictive and generative intelligence. As a senior engineer, you will take ownership of key technical components and ensure that our systems meet the highest standards of performance, reliability, and security. Primary Job Responsibilities: Deliver high-impact AI and ML capabilities that drive insight generation on the PitchBook Platform. Ensure your work contributes to broader business goals and is aligned with the team's strategic priorities Provide hands-on expertise in designing, building, and deploying AI/ML models and services with a focus on NLP, summarization, semantic search, classification, and prediction. Contribute to the development of scalable, high-performance systems that meet production-grade reliability and efficiency standards Support a culture of technical excellence by mentoring peers, sharing knowledge, and participating in code and design reviews. Promote innovation and continuous improvement through collaborative engineering practices Build and optimize models that leverage classifiers, transformers, LLMs, and other NLP techniques to generate meaningful insights from structured and unstructured data. Integrate these models into the broader AI/ML infrastructure in collaboration with partner teams Collaborate with engineering, product management, and data collection teams to ensure models are informed by high-quality data and support strategic product goals Explore and experiment with emerging technologies, methodologies, and tools in the fields of GenAI, NLP, and search. Translate research findings into practical solutions that enhance PitchBook’s AI capabilities Contribute to best practices in model transparency, monitoring, evaluation, and compliance. Help maintain high standards of security, data integrity, and responsible AI use across your projects Participate in the technical evaluation of candida",https://aijobs.ai/job/sr-machine-learning-engineer-1
Backend Software Engineer - Python,Toggle AI,"London,  England,  United Kingdom",Non spécifié,Lead/Principal,,,,"Python, Go","Minimum qualifications Bachelor's degree in Computer Science, related field, or equivalent practical experience. Experience with software development in one or more programming languages, or experience with an advanced degree. Experience with data structures or algorithms in either an academic or industry setting. Preferred qualifications 2 years of experience with Python. Master's degree or PhD in Computer Science or related technical field. Experience with performance, large scale systems data analysis, visualization tools, and/or debugging. Experience developing accessible technologies. Excellent communication skills. Responsibilities Write product or system development code. Review code developed by other engineers and provide feedback to ensure best practices (e.g., style guidelines, checking code in, accuracy, testability, and efficiency). Contribute to existing documentation or educational content and adapt content based on product/program updates and user feedback. Triage product or system issues and debug/track/resolve by analyzing the sources of issues and the impact on hardware, network, or service operations and quality. Participate in, or lead architecture or system design reviews with peers and stakeholders to decide amongst available technologies. About The Job Reflexivity's software engineers drive the development of cutting-edge technologies that transform how millions of users connect, explore information, and engage with the market. Our products must effectively manage vast amounts of data and go far beyond generating investment insights. We seek engineers who bring innovative concepts from diverse fields such as information retrieval, distributed computing, designing large-scale systems, networking, data storage, cybersecurity, artificial intelligence, natural language processing, mobile and UI design - the range continues to expand constantly. As a Software Engineer, you'll contribute to a crucial project aligned with Reflexivity's requirements, with opportunities to transition between teams and projects as our fast-paced business evolves and grows. With your technical expertise you will manage project priorities, deadlines, and deliverables. You will design, develop, test, deploy, maintain, and enhance software solutions. Reflexivity aims to become an inclusive organization that mirrors the globally varied audience benefiting from our products and technology. We firmly believe that a diversity of viewpoints, concepts, and cultures not only enriches our workforce, but also results in the development of superior products and services. At its core, Reflexivity embodies an engineering ethos. We recruit individuals with a wide array of technical proficiencies who are prepared to confront some of technology's most significant hurdles and leave a mark on global users. Within Reflexivity, engineers not only pioneer advancements in the investment space, but they also routinely address scalability and storage solutions, develop large-scale applications, and introduce entirely novel platforms for other developers. Notice. Reflexivity does not accept agency resumes. Please do not forward resumes to our jobs alias, Reflexivity employees or any other organization location. Toggle is not responsible for any fees related to unsolicited resumes Salary Range £50,000  -  £80,000   GBP",https://aijobs.ai/job/backend-software-engineer-python
Senior Applied AI Engineer (f/m/d),Contentful,"London,  England,  United Kingdom",Hybrid,Senior,,,,"JavaScript, Python, TypeScript","About the Opportunity Contentful is looking for a Senior Applied AI Engineer (f/m/d) to deliver high-impact, AI-powered solutions that improve efficiency, reduce manual work, and unlock new capabilities across the business. This is a hands-on role for someone who thrives on solving operational challenges using modern AI technologies. You will work closely with internal stakeholders to identify opportunities where AI can streamline workflows, enable automation, or enhance decision-making. Whether it's building custom tools, integrating AI into existing systems, or prototyping new applications, your work will help teams across the company operate more effectively and innovate faster. This is a builder role for someone who combines engineering skills, curiosity, and a passion for applied AI. You'll be part of the team responsible for turning ideas What to expect? Design and implement AI-powered tools and workflows that automate repetitive tasks, improve accuracy, and expand team capacity. Write code and build internal solutions that leverage LLMs and agentic frameworks to address specific business challenges. Collaborate with teams across the business to understand needs, define requirements, and co-develop scalable solutions. Research and assess AI tools and platforms (e.g., OpenAI, Claude, Google Vertex AI), ensuring alignment with company standards around privacy, security, and usability. Rapidly prototype and test new AI-powered use cases with internal stakeholders, iterating based on feedback. Act as a subject matter expert on applied AI, educating teams on capabilities, tools, and responsible use. Monitor the performance and adoption of AI-powered tools, and continuously improve them based on data and user feedback. What you need to be successful Critical: Professional Background: 7+ years of experience in software engineering, with a focus on building and maintaining internal-facing software. Software Engineering Skills: Proven track record of developing in Python or JavaScript/Typescript, with working knowledge of the other. Automation Experience: Hands-on experience creating automation workflows, scripting, lightweight data pipelines, or using low-code platforms. Collaboration: Evidence of partnering with cross-functional stakeholders, with the ability to translate technical solutions into business impact (e.g., presenting to non-technical teams). High-Impact Engineering: Demonstrated ability to design and launch software that integrates multiple tools, improves workflows, automates processes, and delivers measurable outcomes (e.g., productivity gains, time savings, or adoption metrics). Desirable: Applied AI Skills: Practical experience with integrating OpenAI, Claude, or Google Vertex AI into workflows and automation, either through prompt engineering, fine-tuning, or implementing Retrieval-Augmented Generation. Data Processing: Experience working with text processing, NLP frameworks, or unstructured data pipelines (e.g., NLTK, spaCy, Hugging Face). Policy & Standards Implementation: Demonstrated involvement in aligning technical solutions with AI policy or internal governance standards (e.g., drafting model usage guidelines, running risk assessments, or contributing to responsible AI initiatives). Security & Compliance: Experience working with security teams to ensure AI-powered tools meet organizational security, privacy, and compliance requirements (e.g., access controls, secure deployment reviews, or data handling policies). Domain Experience: Background in building tools or systems for B2B SaaS or enterprise environments. Experimentation & Prototyping: Evidence of rapidly prototyping and iterating on tools or workflows, with examples of evolving prototypes into production-ready solutions. What’s in it for you? Join an ambitious tech company reshaping the way people build digital experiences Full-time employees receive Stock Options for the opportunity to share in the success of our company Fertility and family building benefits, including a lifetime reimbursable wallet to support your growing family. We value Work-Life balance and You Time ! A generous amount of paid time off, including vacation days, sick days,  education days, compassion days for loss, and volunteer days Time off to care for and focus on your growing family Use your personal annual education budget to improve your skills and grow in your career Enjoy a full range of virtual and in-person events, including workshops, guest speakers, and fun team activities, supporting learning and networking exchange beyond the usual work duties An annual wellbeing stipend to care for your physical, financial, or emotional health A monthly communication phone/internet stipend and phone hardware upgrade reimbursement. New hire office equipment stipend for hybrid or distributed employees. Get the gear you need to work at your best. #LI-hybrid Who are we? Contentful is a leading digital experience platform that helps modern businesses meet the gr",https://aijobs.ai/job/senior-applied-ai-engineer-fmd
Staff Post Silicon Validation Engineer (Bringup),Graphcore,"Austin,  Texas,  United States",Hybrid,Lead/Principal,100000.0,258000.0,179000.0,Python,"Staff Post Silicon Validation Engineer (Bringup) Salary $191,100 - $258,500 + Phantom Equity + Benefits Graphcore is a globally recognised leader in Artificial Intelligence computing systems. The company designs advanced semiconductors and data centre hardware that provide the specialised processing power needed to drive AI innovation, while delivering the efficiency required to support its broader adoption. As part of the SoftBank Group, Graphcore is a member of an elite family of companies responsible for some of the world’s most transformative technologies. We are opening a new AI Engineering Campus in Austin which will play a central role in Graphcore's work building the future of AI computing. We are looking to hire Post-Silicon Validation Engineers to join our collaborative, cross-functional development team validating cutting edge, high performance AI chips and platforms. You will play a critical role in supporting new product introductions and post-silicon validation. Working within the Post-Silicon Validation team, you will be involved with bringing first silicon to life, functionally validating it and working closely with many other teams to help it become a fully characterised and working product, reporting project status/progress to program management on a regular basis. You will have the opportunity to, and be responsible for, leading, mentoring, and providing technical guidance to other engineering team members. In this role, you can leverage your experience and industry knowledge to architect and drive implementation of continuous improvements to test infrastructure and processes. The Post-Silicon Validation team sits within the Architecture and Validation team, we are responsible for validation of new silicon when it returns from manufacture, enabling and supporting the production SW and FW teams to bring up their software and also supporting the Silicon Characterisation team. Responsibilities and Duties Plan, design, develop and debug silicon validation tests in bare metal C/C++ on FPGA/Emulator prior to first silicon Deploy silicon validation tests on first silicon and debugging them Develop automated test framework and regression test suites in Python to optimize validation efficiency Collaborate closely with engineers from many other disciplines on a variety of topics Work with Validation and Production Test engineering peers to implement best practices and continuous improvements to test methodologies Analyse test results, identify and debug failures/defects Contribute to shared test and validation infrastructure Provide feedback to architects Essential skills: Strong experience in Bare metal / embedded C/C++ Good knowledge of digital ASICs Be highly motivated, a self starter, and a team player Ability to work across teams and programming languages to find root causes of deep and complex issues Experience of the post-silicon validation process applied in digital ASIC environments Python, Linux Excellent communication skills and the ability to collaborate with others to solve problems Excellent problem-solving, analytical & diagnostic skills Desirable skills: Driver level experience with one or more of the following is highly desirable: PCIe Ethernet Memory technologies (LPDDR, DDR, HBM, …) Other peripherals such as I2C, I3C, SPI, … Good knowledge of mixed-signal building blocks such as PLLs, high speed PHYs and IC control/communication protocols is highly desirable Experience of Arm CPUs , System IP and debug tools Experience of AMBA protocols Understanding of ML applications and their workloads Experience in Characterization, Failure Analysis, Test Development, Statistical analysis, and Customer Support Benefits: In addition to a competitive salary, Graphcore offers a competitive benefits package. We welcome people of different backgrounds and experiences; we’re committed to building an inclusive work environment that makes Graphcore a great home for everyone. We offer an equal opportunity process and understand that there are visible and invisible differences in all of us. We can provide a flexible approach to interview and encourage you to chat to us if you require any reasonable adjustments.",https://aijobs.ai/job/staff-post-silicon-validation-engineer-bringup
Software Engineer I - AI Platform,StubHub,"Aliso Viejo,  California,  United States",Hybrid,Junior,1000.0,2000.0,1500.0,"CI/CD, Machine Learning","StubHub is on a mission to redefine the live event experience on a global scale. Whether someone is looking to attend their first event or their hundredth, we’re here to delight them all the way from the moment they start looking for a ticket until they step through the gate. The same goes for our sellers. From fans selling a single ticket to the promoters of a worldwide stadium tour, we want StubHub to be the safest, most convenient way to offer a ticket to the millions of fans who browse our platform around the world. We’re seeking a Software Engineer – AI Enablement to help shape how StubHub adopts and scales AI across the company. This role is about making AI practical, safe, and valuable by empowering teams to experiment confidently, automate intelligently, and deliver better outcomes faster. You’ll work across technical and business domains to design tools, frameworks, and patterns that make AI accessible to everyone, not just machine learning experts. Why We Need You We’re looking for experienced AI Engineers to lead the development and implementation of AI-driven capabilities across our organization. This role is critical in introducing cutting-edge AI tooling, defining and scaling best practices, and building custom models that solve real business problems. You’ll partner closely with cross-functional teams to identify high-impact use cases, architect and deploy robust AI solutions, and help shape the company’s broader AI strategy. The ideal candidate blends deep technical expertise in machine learning, LLMs, and MLOps with the ability to think strategically, influence stakeholders, and deliver scalable, production-ready systems that create measurable value for the business. Location: Hybrid (3 days in office/2 days remote) – Aliso Viejo, CA or Santa Monica, CA What You'll Do: AI Tooling & Infrastructure Design and implement internal AI platforms and tools that make it easy for teams to build with generative and agentic AI. Develop reusable components for prompt orchestration, model evaluation, and workflow automation. Partner with engineers, data scientists, and product teams to embed AI into StubHub’s core products and internal processes. Define patterns and frameworks for safe, scalable, and effective AI usage. Enablement & Best Practices Lead by example in applying AI to real business challenges from customer support to pricing insights to developer productivity. Navigate ambiguity with curiosity and creativity by shaping direction even when problems aren’t fully defined. Engage deeply with business teams to understand their requirements, challenges, and workflows: translating those insights into innovative, AI-driven solutions. Create playbooks, workshops, and documentation to help teams become confident AI practitioners. Establish principles for prompt engineering, data quality, and human-in-the-loop feedback. Foster a culture of responsible experimentation and continuous improvement. Agentic & Generative AI Development Build and optimize AI agents that enhance workflows, automate tasks, and provide insights. Prototype and refine LLM-powered solutions using modern frameworks and APIs. Track performance, measure impact, and evolve solutions over time based on real-world usage. What You've Done: 1-2 years of hands-on experience in software engineering , AI development , or technical solution delivery in internships Delivered real impact through AI, automation, or data-driven solutions — whether as an engineer, analyst, or product builder. Collaborated across teams to identify use cases, define success, and deploy working systems that improved outcomes. Adapted and learned fast , experimenting with new AI tools and frameworks to find practical, scalable solutions. Balanced hands-on building with strategic thinking — understanding when to ship, when to experiment, and when to scale. Experience integrating or deploying AI systems (e.g., chatbots, assistants, RAG pipelines, or workflow agents). Comfortable working with modern software environments (cloud platforms, APIs, version control, CI/CD). Excellent communication and storytelling skills — able to translate technical work into clear business value. It would be nice if you have : Experience enabling organizational AI adoption or building internal AI platforms or tools. Familiarity with LLM frameworks (LangChain, OpenAI, Anthropic, HuggingFace, etc.). Understanding of data privacy, compliance, and ethical AI practices (GDPR, CCPA). Background in change management, developer enablement, or digital transformation. Degree in Computer Science, Data Science, or a related technical field (or equivalent hands-on experience). What We Offer: Accelerated Growth Environment : An environment designed for swift skill and knowledge enhancement, where you have the autonomy to lead experiments and tests on a massive scale. Top Tier Compensation Package : Competitive base, equity, and upside that tracks with your impact. Flexible Time Of f: Enjoy unlimited Flex ",https://aijobs.ai/job/software-engineer-i-ai-platform
Engineering Manager,Forethought,"Ontario,  Canada",Non spécifié,Lead/Principal,,,,"Flask, Python, Elasticsearch, Redis, MongoDB, FastAPI, Django, Docker, Kubernetes","Launched in 2018, Forethought is the first AI-native platform for enterprise customer support, built on a multi-agent architecture for omnichannel resolution. Trusted by leading companies like Upwork, Grammarly, Airtable, and Datadog, Forethought’s AI agents resolve billions of monthly support issues. The company has raised $115M+ in venture funding from top investors, including Blue Cloud Ventures, NEA, Village Global, and Sound Ventures, G2 has recognized Forethought as a High Performer in 2024 and Mid-Market Leader, Best Est. ROI, and Easiest to Do Business With in Customer Support for 2025. We’re looking for talented Engineering Manager with a growth mindset; managers who thrive on solving complex challenges and want to help shape the future of AI-driven customer support. As a manager on the team, you’ll play a critical role in managing the team of engineers, helping with technical architecture, mentoring, while still being able to jump in and support on core development. Our product has over 1 billion monthly interactions so the work you and your team will do has a big impact for our customers. You will have an opportunity to lead a team building a  product that is a leader in our space using the latest models and techniques in AI. Our tech stack leverages modern technologies, including Docker, Kubernetes, Redis, MongoDB, and ElasticSearch What You'll Be Doing (Responsibilities): Manage a team of product engineers (Full-Stack, Frontend, and Backend engineers) Design engineering services that power Forethought’s core AI features, directly impacting the customer experience across our platform. Collaborate with product and design teams to translate user needs into scalable solutions that enhance customer support automation. Scale and optimize our product to handle over 1 billion monthly interactions, ensuring high performance, reliability, and efficiency across all customer touchpoints. Partner with AI/ML engineers to integrate LLM-based capabilities into production workflows, with a focus on reliability, observability, and speed. Drive technical excellence by owning projects end-to-end—from architecture and implementation to deployment and monitoring. Who You Are (Requirements): A Bachelor’s or Master’s degree in Computer Science, Statistics, Informatics, Information Systems, or a related field is preferred. Demonstrated 7+ years of experience in a software engineering role is required. Experience managing a team of engineers. Expertise in Python is essential with proficiency in one of the mainstream Python frameworks (FastAPI/Django/Flask) Proven experience in constructing large-scale distributed systems is necessary. Ability to craft high quality, well-tested code to address customer requirements. Experience with MongoDB, Redis, and Elasticsearch is preferred. Experience working with generative AI frameworks (e.g., LangChain, RAG pipelines, multi-agent systems) is a plus. Familiarity with integrating and building applications on top of large language models (e.g., OpenAI, Anthropic, open-source LLMs) is highly valued.",https://aijobs.ai/job/engineering-manager-37
"Staff Engineer, AI/ML for Circuit Design","Samsung Semiconductor, Inc.","San Jose,  California,  United States",Hybrid,Senior,0.0,243000.0,121500.0,"Scikit-learn, Python, Machine Learning, TensorFlow, PyTorch","Please Note: To provide the best candidate experience amidst our high application volumes, each candidate is limited to 10 applications across all open jobs within a 6-month period. Advancing the World’s Technology Together Our technology solutions power the tools you use every day--including smartphones, electric vehicles, hyperscale data centers, IoT devices, and so much more. Here, you’ll have an opportunity to be part of a global leader whose innovative designs are pushing the boundaries of what’s possible and powering the future. We believe innovation and growth are driven by an inclusive culture and a diverse workforce. We’re dedicated to empowering people to be their true selves. Together, we’re building a better tomorrow for our employees, customers, partners, and communities. Our team is at the forefront of applying machine learning to real-world chip design for OLED display applications. As part of a dynamic group of researchers, engineers, you will collaborate on innovative projects that transform data into insights and breakthrough discoveries of new circuits with high performance for next-generation displays. Samsung Display Lab is hiring an AI expert with background in circuit/pixel layout design, placement and routing in circuits, parasitic capacitance extraction, and circuit evaluation by fusing physics-based methods with modern AI/ML methods. You will drive AI-assisted panel layout and architect pixel/backplane circuits, including placement and routing, build high-fidelity surrogates for parasitic capacitance prediction, and optimization of panel layout area. As an EDA engineer, you will support the development, verification, and optimization of pixel circuits for advanced displays (OLED, micro-LED, etc). Location:  Daily onsite presence at our San Jose, CA office / U.S. headquarters in alignment with our Flexible Work policy. What You’ll Do Develop EDA design workflows for pixel circuits for OLEDs Create automatic scripts for schematic generation and layout assembly Apply Reinforcement Learning and/or Diffusion models for placement and routing (P&R) and compare their efficacy with classical P&R algorithms Build AI-based surrogate models for parasitic capacitance extraction Apply Graph Neural Networks (GNN) for circuit design and/or surrogate models for circuit parameters estimation Apply design of experiments (DoE) and optimization methods to accelerate simulation and parameter tuning Develop optimization algorithms for pixel array compaction Contribute to continuous improvement of model accuracy through active learning and uncertainty analysis What You Bring BS Computer Science or equivalent with a minimum of 5+ years or a MS in Computer Science with 3+ years or PhD 0+ years in Electrical Engineering/Computer Engineering/Applied Physics (or equivalent experience) Proficiency with SPICE/Spectre/HSPICE/Cadence Virtuoso/ADE; layout and parasitic extraction Strong Python and ML fundamentals (PyTorch or TensorFlow, scikit-learn/NumPy/Pandas) Experience building and validating surrogate models and running multi-objective optimization Experience with Reinforcement Learning (RL), Diffusion models, and Graph Neural Networks (GNN) Experience with Cadence Innovus, Synopsys Fusion Compiler, Aprisa, GDSFactory, KLayout is a plus Hands-on experience with EDA tools for layout assembly, placement and routing, parasitic capacitance extraction, pixel circuit area compaction, etc. Knowledge of classical algorithms for placement and routing in chip design Publications/patents in display, EDA, or ML-for-hardware Solid analog/digital circuit fundamentals; hands-on OLED pixel/gate driver design You’re inclusive, adapting your style to the situation and diverse global norms of our people An avid learner, you approach challenges with curiosity and resilience, seeking data to help build understanding You’re collaborative, building relationships, humbly offering support and openly welcoming approaches Innovative and creative, you proactively explore new ideas and adapt quickly to change #LI-VL1 What We Offer The pay range below is for all roles at this level across all US locations and functions. Individual pay rates depend on a number of factors—including the role’s function and location, as well as the individual’s knowledge, skills, experience, education, and training. We also offer incentive opportunities that reward employees based on individual and company performance. This is in addition to our diverse package of benefits centered around the wellbeing of our employees and their loved ones. In addition to the usual Medical/Dental/Vision/401k, our inclusive rewards plan empowers our people to care for their whole selves. An investment in your future is an investment in ours. Give Back With a charitable giving match and frequent opportunities to get involved, we take an active role in supporting the community. Enjoy Time Away You’ll start with 4+ weeks of paid time off a year, plus holidays and sick leave, to r",https://aijobs.ai/job/staff-engineer-aiml-for-circuit-design
Senior Software Engineer (ML/Graphics),PlayStation Global,"United States,  San Mateo,  CA",Hybrid,Lead/Principal,300000.0,289000.0,294500.0,"Rust, Machine Learning, TensorFlow, PyTorch","Why PlayStation? PlayStation isn’t just the Best Place to Play — it’s also the Best Place to Work. Today, we’re recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation®5, PlayStation®4, PlayStation®VR, PlayStation®Plus, acclaimed PlayStation software titles from PlayStation Studios, and more. PlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Group Corporation. Join us in shaping the future of play. At PlayStation, we build GPU and machine learning systems that power real-time experiences across console, cloud, and game streaming. Games run on servers and stream frames to clients in real time, where advanced ML techniques improve visual quality, latency, and efficiency. Through developing tools like CnnForge, we transform ONNX models into optimized GPU shaders, enabling inference directly on PlayStation hardware and unlocking new possibilities in neural rendering, super-resolution, denoising, and perceptual video compression. What You'll Do You will work across GPU, ML, and systems engineering to create frameworks that make games more lifelike and responsive. Your contributions will include: Designing and optimizing GPU inference pipelines for ML models in real-time media and game streaming Deploying models efficiently on PlayStation hardware, converting ONNX definitions into high-performance shader code Building tools and workflows that speed up experimentation and deployment of ML-powered GPU systems Applying advanced optimizations such as kernel fusion, memory access coalescing, and operator specialization to meet strict latency targets Helping shape the long-term direction of AI-driven GPU systems at PlayStation What We're Looking For We value curiosity and technical excellence. You’re a strong fit if you bring most of the following: Background in GPU computing, computer graphics, machine learning, or computer vision Proficiency in C++ and/or Rust, with focus on performance-critical code Experience with GPU programming, profiling, and optimizations (CUDA, Vulkan, DirectX, or Metal) Familiarity with ML frameworks such as PyTorch, TensorFlow, or ONNX Track record of delivering complex systems into production Why Join Us At PlayStation, you’ll advance GPU and ML technology at scale, from consoles to cloud to streaming. You’ll work on projects that directly impact millions of players, while accessing the latest hardware, development tools, and infrastructure. We also offer comprehensive benefits including health coverage, retirement plans, paid time off, parental leave, wellness programs, and access to PlayStation games and services. We build technology that makes play more immersive for everyone, and we’d like you to be part of it. Our Commitment We strive to create an environment where people of all backgrounds and experiences can do their best work. If you need support or accommodation during the hiring process, let us know, and we’ll work with you. Please refer to our Candidate Privacy Notice for more information about how we process your personal information, and your data protection rights. At SIE, we consider several factors when setting each role’s base pay range, including the competitive benchmarking data for the market and geographic location. Please note that the base pay range may vary in line with our hybrid working policy and individual base pay will be determined based on job-related factors which may include knowledge, skills, experience, and location. In addition, this role is eligible for SIE’s top-tier benefits package that includes medical, dental, vision, matching 401(k), paid time off, wellness program and coveted employee discounts for Sony products. This role also may be eligible for a bonus package. Click here to learn more. The estimated base pay range for this role is listed below. $193,300  -  $289,900   USD Equal Opportunity Statement: Sony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to gender (including gender identity, gender expression and gender reassignment), race (including colour, nationality, ethnic or national origin), religion or belief, marital or civil partnership status, disability, age, sexual orientation, pregnancy, maternity or parental status, trade union membership or membership in any other legally protected category. We strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond. PlayStation is a Fair Chance employer and qualified applicants with arrest and conviction records will be considered for employment.",https://aijobs.ai/job/senior-software-engineer-mlgraphics
"Director of Engineering, AI & ML, Data Collections",PitchBook Data,"Seattle,  Washington,  United States",Remote,Senior,0.0,340000.0,170000.0,"Machine Learning, TensorFlow, PyTorch","At PitchBook, a Morningstar company, we are always looking forward. We continue to innovate, evolve, and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy, and fun that reverberates throughout the company. Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast, and do it all over again in the pursuit of excellence. If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you. About the Role: The Data Collection AI/ML team sits at the intersection of automation, AI, and data quality. The team’s mission is to accelerate and scale PitchBook’s data coverage by applying advanced ML models to identify, extract, and validate entities, relationships, and key insights from vast collections of structured and unstructured sources, including filings, PDFs, and market documents. As the Director of the Data Collection AI/ML team, you will partner closely with Data Operations, Data Collections Product and Engineering teams to deliver seamless, intelligent data pipelines that transform raw inputs into high-quality, actionable data. As the Director of Data Collection AI & ML you will lead the strategy, vision, and execution of AI and ML initiatives focused on automating PitchBook’s data extraction, enrichment, and validation workflows. Your organization will be responsible for building intelligent systems that ensure PitchBook’s data collection is as accurate, comprehensive, and timely as possible, leveraging cutting-edge document AI, OCR, and entity resolution techniques applied to financial documents and other proprietary data sources. In this highly visible leadership role, you will manage a global team of 15+ data scientists and machine learning engineers, driving both innovation and operational excellence. You will define the roadmap for automation and enrichment across multiple data domains and ensure scalable, production-grade AI systems that directly power PitchBook’s data ingestion pipelines and platform accuracy. Your leadership will guide the design and deployment of AI-driven extraction and enrichment models, including document classification, named entity recognition, relationship extraction, and quality validation systems. You will also play a key role in shaping cross-functional data and AI strategy in collaboration with Product, Data Operations, and the client-facing Insights AI/ML teams, ensuring consistency, reliability, and alignment with enterprise data objectives. This role demands a visionary yet hands-on leader — one who can balance strategic direction with technical credibility, and who can influence across teams and executive levels while ensuring the continued professional development of a globally distributed technical team. In addition to driving product impact, this role offers an opportunity to shape PitchBook’s growing presence and technical reputation in the AI and ML space. We are looking for individuals who are active contributors to the broader AI community through peer-reviewed research, technical publications, or open-source initiatives. Candidates who have authored conference papers or patents and who are excited to explore the frontiers of generative AI, LLMs, and applied NLP will be well-positioned to help us both advance our internal capabilities and deepen trust with our customers through thought leadership. Primary Job Responsibilities: Define and execute the AI & ML strategy for data collection, extraction, and enrichment automation aligned with PitchBook’s long-term data strategy Partner with senior leadership to identify high-impact opportunities for AI-driven automation and cost reduction in data collection workflows Establish success metrics and operational KPIs for automation accuracy, throughput, and coverage improvement Lead, hire, and develop a high-performing global team of data scientists and ML engineers; define team structure, roles, and growth paths that align with organizational goals Foster a culture of innovation, accountability, inclusion, and continuous improvement across distributed offices Champion hiring, mentorship, and professional development initiatives to grow internal AI/ML talent Elevate engineering excellence through code reviews, design reviews, and technical guidance for ML engineers and scientists Act as a multiplier by shaping best practices for experimentation, model evaluation, responsible AI, and scalable ML engineering Guide teams across the organization toward cohesive, reusable, and standards-aligned architectures Collaborate closely with Engineering, Product Management, and Data Operations to en",https://aijobs.ai/job/director-of-engineering-ai-ml-data-collections-1
"Senior Software Engineer, AI Data",AssemblyAI,"London,  United Kingdom",Remote,Senior,,,,"Python, Docker, GCP, Machine Learning","About AssemblyAI At AssemblyAI, we’re building at the forefront of Speech AI, creating powerful models for speech-to-text and speech understanding available through a straightforward API. With more than 200,000 developers building on our API and over 5,000 paying customers, AssemblyAI is helping unlock and support the next generation of powerful, meaningful products built with AI. Progress in AI is moving at an unprecedented pace– and our team is made up of experts in AI research that are focused on making sure that our customers are able to stay on the cutting edge, with production-ready AI models that are constantly updating and improving as our team continues to improve accuracy, latency, and what’s possible with Speech AI. Our models consistently rank highest in industry benchmarks for accuracy, outperforming models from Google and Amazon, and up to 30% fewer hallucinations than OpenAI’s Whisper. Our models power more than 2 billion end-user experiences each day, helping companies better understand customer feedback, run more productive meetings with automated meeting notes, and helping improve childhood literacy via ed tech tools. We’ve raised funding by leading investors including Accel, Insight Partners, Y Combinator’s AI Fund, Patrick and John Collision, Nat Friedman, and Daniel Gross. We’re a remote team looking to build one of the next great AI companies, and are looking for driven, talented people to help us get there! About the Role We're seeking an exceptional Senior Software Engineer to join our AI Data team. This role is focused on building robust, scalable systems that power our AI data platform. You'll work on high-impact projects that directly influence our ability to train, evaluate and deploy models at scale, with a strong emphasis on software engineering excellence, system reliability, and code quality. As a Senior Engineer, you'll drive technical execution within your team, taking ownership of significant features and components. You should be passionate about writing clean, maintainable code, implementing comprehensive testing strategies, and continuously improving engineering practices. This role requires close collaboration with researchers, platform engineers, and other stakeholders. You'll need to balance technical excellence with pragmatic delivery in a fast-paced startup environment. What You’ll Do Architect Next-Gen AI Data Infrastructure Design scalable, future-proof data platforms optimized for AI research workloads Build efficient self-serve data processing pipelines leveraging GCP's advanced services Implement cost-effective storage and monitoring solutions for ML at scale Create flexible training resource management with intelligent queuing Optimize resource allocation for maximum training efficiency Participate in on-call rotation to ensure system reliability Advance Technical Excellence Lead adoption of cutting-edge ML tools and frameworks, continuously evaluating and integrating best-in-class solutions Streamline existing workflows while introducing new tooling that further reduces complexity Enhance our tooling and documentation to accelerate team velocity and maintain our competitive edge Implement guardrails for cost, quality, and performance Identify and eliminate technical bottlenecks in the data processing and training pipelines What You’ll Need 5+ years of professional software engineering experience Strong proficiency in Python and SQL with demonstrated ability to write production-quality code Solid understanding of software engineering fundamentals: Data structures and algorithms System design and architectural patterns Testing strategies (unit, integration, end-to-end) Code review practices and technical collaboration Experience with: RESTful APIs and distributed systems concepts Containerization (Docker) and basic cloud infrastructure Track record of delivering high-quality software in a team environment Ability to thrive in a startup environment with changing priorities and rapid iteration Preferred Experience with GCP services (BigQuery, GCS, Cloud Run, GKE) Familiarity with distributed processing frameworks (Apache Beam, PySpark) Experience with workflow orchestration tools (Airflow, Prefect, Dagster) Understanding of ML/AI infrastructure and data pipelines Experience with monitoring and observability tools (Datadog) Experience working with researchers directly Background in data engineering roles What We're Looking For This role requires someone who is: Excellent at software fundamentals - You write code that others want to emulate Quality-focused - You care deeply about testing, documentation, and maintainability Customer-aware - You understand how your work impacts research experience and business outcomes Collaborative - You work well with diverse stakeholders and help others succeed Growth-minded - You're curious, eager to learn, and want to expand into platform and infrastructure engineering Pragmatic - You balance perfection with delivery and unders",https://aijobs.ai/job/senior-software-engineer-ai-data
Staff Machine Learning Engineer,Speechmatics,"London,  England,  United Kingdom",Hybrid,Junior,2000.0,3000.0,2500.0,"Python, Go, Machine Learning, TensorFlow, PyTorch","We are hiring a Staff Machine Learning Engineer to work on translating cutting-edge research into ambitious, customer-centric speech solutions. As innovators in speech technology, our mission is to Understand Every Voice — a vision that has propelled us to be world leaders of Speech AI. Fuelled by innovation, inclusivity, and a passion for making a global impact through world-leading Speech AI, we're looking for an experienced ML Team Lead to accelerate our efforts towards exceptional speech solutions. Our Modelling Team builds and trains a broad spectrum of models, including large self-supervised architectures, advancing Speechmatics’ mission to provide the most accurate speech recognition technology worldwide. It also ensures their deployment into production, working with the latest developments in ML, but also with the best practices for software engineering and model serving. In this role, You will develop and deploy advanced speech systems that power our products, and collaborate with cross-functional teams to deliver scalable, high-performance solutions that deliver business impact. What you’ll be doing: Develop and deploy ML models, translating research into scalable, user-centred solutions Optimise ML models for speed, accuracy, and cost efficiency Evaluate and integrate cutting-edge approaches into our ML stack Collaborate cross-functionally to align initiatives with business goals Mentor junior engineers and foster a culture of technical excellence Contribute to technical strategy and roadmap to achieve ambitious strategic goals Who we are looking for: Deep understanding of the modern Machine Learning stack, for example: - Knowledge of contemporary transformer architectures, related concepts (e.g., GQA , KV -caching) and best practices - Expertise in distributed training techniques - Familiarity with optimisation strategies for model inference (e.g., dynamic batching, flash attention, speculative decoding) Proven track record of developing deploying models at scale Proficiency in Python, ML frameworks (TensorFlow, PyTorch), and experience with cloud platforms Strong familiarity with software engineering practices and ML testing frameworks User-centricity, with understanding how ML solutions address customer needs We encourage you to apply even if you do not feel you match all of the requirements exactly. The list of requirements is intended to show the kinds of experience and qualities we’re looking for, but it is not exhaustive. If you are interested in the role, the team, and our mission, we would love to consider your application. We are always open to conversations and look forward to hearing from you. Who we are: Speechmatics is the leading expert in Speech Intelligence, and uses AI and Machine Learning to unlock business value in human speech worldwide. We work with an amazing mix of global companies, and our technology can integrate into our customers stack irrespective of their industry or use case – making it the go-to solution to harness useful information from speech. Joining us means working with some of the smartest minds around the world, focused on cutting-edge projects and deploying the latest techniques to disrupt the market. We believe in putting people first; we’ll do all we can to help you develop your skills and give you the tools you need to thrive. Our Focus Fridays give you an undisturbed day of focus, offset with Together Tuesdays when we have our team meetings, so you've always got the right balance. We have structured a hybrid approach that includes 2-3 designated office days each week. This arrangement ensures that while we embrace the advantages of remote work, we also maintain the vital connection and synergy that only in-person interactions can foster. This is only the beginning; we’re looking for amazing people like you to continue our journey… What we can offer you: No matter what stage of your career you’re at - from paid internships and first-job opportunities through to management and senior positions - we’ll support you with the training and development needed to reach your career aspirations with us. There really is no shortage of opportunities here for you to get involved and collaborate with those around you to deliver your best work. We offer incredibly flexible working, regular company lunches, and birthday celebrations. But that’s not all. We’ve spoken to our teams to find out what they want. From Private Medical, and Dental for you and your family, through to global working opportunities, a generous holiday allowance and pension/401K matching, we want to make sure our employees and their families are looked after. Every employee will receive a working from home allowance for tech or home office equipment (on top of your choice of laptop and accessories of course). Our approach to parental leave is designed to support employees globally. While this varies by geo, we have support in place for parents (including adoption assistance and reproductive health s",https://aijobs.ai/job/staff-machine-learning-engineer-445
Senior Director/VP - Head of AI Engineering,CommerceIQ,"Toronto,  Ontario,  Canada",Remote,Senior,,,,"Python, Java, Machine Learning, TensorFlow, PyTorch","Company Overview CommerceIQ’s AI-powered digital commerce platform is revolutionizing the way brands sell online. Our unified ecommerce management solutions empower brands to make smarter, faster decisions through insights that optimize the digital shelf, increase retail media ROI and fuel incremental sales across the world’s largest marketplaces. With a global network of more than 900 retailers, our end-to-end platform helps 2,200+ of the world’s leading brands streamline marketing, supply chain, and sales operations to profitably grow market share in more than 50 countries. 10 out of the top 12 CPG brands work with us, including Coca-Cola, Nestle, Colgate-Palmolive, and Mondelez. We’ve raised over $200M from some of the top investors including SoftBank, Insight Partners, and Madrona. Learn more at commerceiq.ai . The Role: We're looking for an Engineering Leader with a Data Science / Machine Learning background to head the incubation of CommerceIQ’s next generation of AI-driven SaaS solutions. The Head of AI Engineering is both hands-on and leadership-focused : you will act as a player-coach , directly shaping the technical architecture of our AI platform while building and mentoring a team of engineers. You will report directly to our cofounders to design and deliver advanced AI and agentic applications that push the boundaries of what is possible in applied AI for commerce. You will be accountable for scaling AI systems from research through production, ensuring that they create measurable business impact for the world’s largest brands. This role is ideal for a technical leader who has both trained models and shipped them into production , built agentic applications , and has a deep understanding of machine learning systems at scale . This is a remote role based out of Toronto. Please note that we are only considering candidates located in the Toronto area for this role. What You'll Do: Partner directly with the cofounders to set and execute the AI engineering strategy. Hire, lead, and mentor a founding AI engineering team within our incubation group, growing both technical depth and organizational capability. Act as a player-coach : contribute hands-on to architecture, model training, and backend engineering while scaling a team around you. Design and build scalable ML infrastructure to support model training, fine-tuning, deployment, and monitoring at production scale. Lead the development of agentic applications , including designing, training, and launching agents that operate in real-world customer environments. Establish best practices for data quality, labeling, and ML pipelines, enabling rapid experimentation and continuous improvement. Drive responsible AI development by ensuring reliability, ethics, safety, and performance in all models and agents shipped to production. Collaborate closely with product, data science, and business stakeholders to translate research breakthroughs into customer-facing features. Set engineering standards and build a culture of technical excellence, innovation, and accountability. What You'll Bring: 5+ years of experience in backend software engineering, with 2+ years leading AI/ML teams . Hands-on experience training AI/ML models , including foundation models, fine-tuned models, or specialized domain models. Proven experience building and deploying agentic applications , with deep knowledge of agent design patterns and orchestration. Strong track record of launching AI models and agents into production environments at scale. Advanced expertise in machine learning, deep learning, and reinforcement learning . Experience designing scalable data systems and pipelines for training and inference. Fluency in backend and ML-oriented programming languages such as Python, Java, Scala, or C++ . Knowledge of modern ML toolkits and frameworks (PyTorch, TensorFlow, Hugging Face, LangChain, Ray, etc.). Strong ability to balance hands-on technical depth with leadership, mentoring, and organizational building. Excellent communication and influencing skills, with experience working directly with senior executives or founders. Bachelor’s or Master’s degree in Computer Science, Mathematics, or a related field. Check out our LinkedIn page to learn more about what it’s like to work at CommerceIQ! We are an equal opportunity employer and value diversity at our company. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, disability status or any other category prohibited by applicable law.",https://aijobs.ai/job/senior-directorvp-head-of-ai-engineering
Senior AI Engineer,Apollo.io,"Remote,  Canada; Remote,  United States",Remote,Senior,0.0,260000.0,130000.0,"Azure, AWS, Python, Go, GCP","Apollo.io is the leading go-to-market solution for revenue teams, trusted by over 500,000 companies and millions of users globally, from rapidly growing startups to some of the world's largest enterprises. Founded in 2015, the company is one of the fastest growing companies in SaaS, raising approximately $250 million to date and valued at $1.6 billion. Apollo.io provides sales and marketing teams with easy access to verified contact data for over 210 million B2B contacts and 35 million companies worldwide, along with tools to engage and convert these contacts in one unified platform. By helping revenue professionals find the most accurate contact information and automating the outreach process, Apollo.io turns prospects into customers. Apollo raised a series D in 2023 and is backed by top-tier investors, including Sequoia Capital, Bain Capital Ventures, and more, and counts the former President and COO of Hubspot, JD Sherman, among its board members. About Apollo.io Apollo.io is the leading go-to-market solution for revenue teams, trusted by over 500,000 companies and millions of users globally, from rapidly growing startups to some of the world's largest enterprises. Founded in 2015, the company is one of the fastest growing companies in SaaS, raising approximately $250 million to date and valued at $1.6 billion. Apollo.io provides an end-to-end go-to-market platform that enables sales and marketing teams to source prospects from our database of 210 million B2B contacts and 35 million companies, execute personalized email outreach campaigns, automate booking flows, and manage deals—all within one unified platform. Apollo raised a Series D in 2023 and is backed by top-tier investors, including Sequoia Capital, Bain Capital Ventures, and more, and counts the former President and COO of Hubspot, JD Sherman, among its board members. We are AI Native Apollo.io is an AI-native company built on a culture of continuous improvement. We're on the front lines of driving productivity for our customers—and we expect the same mindset from our team. If you're energized by finding smarter, faster ways to get things done using AI and automation, you'll thrive here. Your Role & Mission As a Senior AI Engineer on our AI Engineering team, you will be responsible for building and productionizing advanced AI systems powered by Large Language Models (LLMs) and intelligent agents. You'll work on critical Apollo capabilities including our AI Assistant, Autonomous AI Agents, Deep Research Agents, Conversational Assistant, Semantic Search, Search Personalization, and AI Power Automation features that directly impact millions of users' productivity. The mission of our AI teams is to leverage Apollo's massive scale data and cutting-edge AI to understand and predict user behaviors, personalize experiences, and optimize every stage of the customer journey through intelligent automation. What You'll Be Working On AI Assistant & Agent Systems Agent Architecture & Implementation : Build sophisticated multi-agent systems that can reason, plan, and execute complex sales workflows Context Management : Develop systems that maintain conversational context across complex multi-turn interactions LLM and Agentic Platforms : Build scalable large language model and agentic platforms that enable widespread adoption and viability of agent development within the Apollo ecosystem Backend Systems: Build back-end systems necessary to support the agents. AI features: Conversational AI, Natural Language Search, Personalized Email Generation and similar AI features Classical AI/ML (Optional Focus) Search Scoring & Ranking : Develop and improve recommendation systems and search relevance algorithms Entity Extraction : Build models for automatic company keywords, people keywords, and industry classification Lookalike & Recommendation Systems : Create intelligent matching and suggestion engines Key Responsibilities Design and Deploy Production LLM Systems : Build scalable, reliable AI systems that serve millions of users with high availability and performance requirements Agent Development : Create sophisticated AI agents that can chain multiple LLM calls, integrate with external APIs, and maintain state across complex workflows Prompt Engineering Excellence : Develop and optimize prompting strategies, understand trade-offs between prompt engineering vs fine-tuning, and implement advanced prompting techniques System Integration : Build robust APIs and integrate AI capabilities with existing Apollo infrastructure and external services Evaluation & Quality Assurance : Implement comprehensive evaluation frameworks, A/B testing, and monitoring systems to ensure AI systems meet accuracy, safety, and reliability standards Performance Optimization : Optimize for cost, latency, and scalability across different LLM providers and deployment scenarios Cross-functional Collaboration : Work closely with product teams, backend engineers, and stakeholders to translate busines",https://aijobs.ai/job/senior-ai-engineer-437
Senior Machine Learning Engineer,Speechmatics,"Cambridge,  England,  United Kingdom",Hybrid,Senior,2000.0,3000.0,2500.0,"Go, Machine Learning","We are hiring a Senior Machine Learning Engineer to contribute to cutting-edge Research & Development. As innovators in speech technology, our mission is to Understand Every Voice—a vision that has propelled us to be world leaders of Voice AI, consisting of STT, TTS, and Flow; our brand new Conversational AI platform. Fuelled by innovation, inclusivity, and a passion for making a global impact through world-leading Speech AI, we're looking for an experienced Machine Learning Engineer to accelerate our efforts towards exceptional speech solutions. Our Modelling Team trains diverse models, including large self-supervised ones, supporting Speechmatics towards being the most accurate speech recognition system globally. It also ensures their deployment into production, working with the latest developments in ML, but also with the best engineering practices for software engineering and model serving. What you’ll be doing: Work on complex R&D projects, with a diverse group of engineers, to achieve ambitious goals. Stay current with the latest developments in Machine learning. Execute high-impact projects to ensure team success. Work collaboratively across departments and mentor team members (where appropriate). Who we are looking for: Demonstrated experience in collaboratively pursuing ambitious R&D agendas. Precise attention to detail, but is also aware of how the big picture relates to company goals, and where the field of Machine Learning is headed towards. Understanding of the modern Machine Learning stack, for example: - Knowledge of contemporary transformer architectures (e.g., GQA, KV-caching) and best practices. - Experience in distributed training techniques. - Familiarity with optimisation strategies for model inference (e.g., dynamic batching, flash attention, speculative decoding). With preferred backgrounds covering some of the following: - Publications in top-tier conferences. - Contributions to popular open-source repositories. - Technical writing skills as evidenced by relevant publications or blogs. We encourage you to apply even if you do not feel you match all of the requirements exactly. The list of requirements is intended to show the kinds of experience and qualities we’re looking for, but it is not exhaustive. If you are interested in the role, the team, and our mission, we would love to consider your application. We are always open to conversations and look forward to hearing from you. Who we are: Speechmatics is the leading expert in Speech Intelligence, and uses AI and Machine Learning to unlock business value in human speech worldwide. We work with an amazing mix of global companies, and our technology can integrate into our customers stack irrespective of their industry or use case – making it the go-to solution to harness useful information from speech. Joining us means working with some of the smartest minds around the world, focused on cutting-edge projects and deploying the latest techniques to disrupt the market. We believe in putting people first; we’ll do all we can to help you develop your skills and give you the tools you need to thrive. Our Focus Fridays give you an undisturbed day of focus, offset with Together Tuesdays when we have our team meetings, so you've always got the right balance. We have structured a hybrid approach that includes 2-3 designated office days each week. This arrangement ensures that while we embrace the advantages of remote work, we also maintain the vital connection and synergy that only in-person interactions can foster. This is only the beginning; we’re looking for amazing people like you to continue our journey… What we can offer you: No matter what stage of your career you’re at - from paid internships and first-job opportunities through to management and senior positions - we’ll support you with the training and development needed to reach your career aspirations with us. There really is no shortage of opportunities here for you to get involved and collaborate with those around you to deliver your best work. We offer incredibly flexible working, regular company lunches, and birthday celebrations. But that’s not all. We’ve spoken to our teams to find out what they want. From Private Medical, and Dental for you and your family, through to global working opportunities, a generous holiday allowance and pension/401K matching, we want to make sure our employees and their families are looked after. Every employee will receive a working from home allowance for tech or home office equipment (on top of your choice of laptop and accessories of course). Our approach to parental leave is designed to support employees globally. While this varies by geo, we have support in place for parents (including adoption assistance and reproductive health services) to ensure they have the time and financial resources needed to care for their growing families. At Speechmatics, our mission is simple: Understand Every Voice out there. That's not just about our tech – it's t",https://aijobs.ai/job/senior-machine-learning-engineer-1772
Staff Machine Learning Engineer,Speechmatics,"Cambridge,  England,  United Kingdom",Hybrid,Junior,2000.0,3000.0,2500.0,"Python, Go, Machine Learning, TensorFlow, PyTorch","We are hiring a Staff Machine Learning Engineer to work on translating cutting-edge research into ambitious, customer-centric speech solutions. As innovators in speech technology, our mission is to Understand Every Voice — a vision that has propelled us to be world leaders of Speech AI. Fuelled by innovation, inclusivity, and a passion for making a global impact through world-leading Speech AI, we're looking for an experienced ML Team Lead to accelerate our efforts towards exceptional speech solutions. Our Modelling Team builds and trains a broad spectrum of models, including large self-supervised architectures, advancing Speechmatics’ mission to provide the most accurate speech recognition technology worldwide. It also ensures their deployment into production, working with the latest developments in ML, but also with the best practices for software engineering and model serving. In this role, You will develop and deploy advanced speech systems that power our products, and collaborate with cross-functional teams to deliver scalable, high-performance solutions that deliver business impact. What you’ll be doing: Develop and deploy ML models, translating research into scalable, user-centred solutions Optimise ML models for speed, accuracy, and cost efficiency Evaluate and integrate cutting-edge approaches into our ML stack Collaborate cross-functionally to align initiatives with business goals Mentor junior engineers and foster a culture of technical excellence Contribute to technical strategy and roadmap to achieve ambitious strategic goals Who we are looking for: Deep understanding of the modern Machine Learning stack, for example: - Knowledge of contemporary transformer architectures, related concepts (e.g., GQA , KV -caching) and best practices - Expertise in distributed training techniques - Familiarity with optimisation strategies for model inference (e.g., dynamic batching, flash attention, speculative decoding) Proven track record of developing deploying models at scale Proficiency in Python, ML frameworks (TensorFlow, PyTorch), and experience with cloud platforms Strong familiarity with software engineering practices and ML testing frameworks User-centricity, with understanding how ML solutions address customer needs We encourage you to apply even if you do not feel you match all of the requirements exactly. The list of requirements is intended to show the kinds of experience and qualities we’re looking for, but it is not exhaustive. If you are interested in the role, the team, and our mission, we would love to consider your application. We are always open to conversations and look forward to hearing from you. Who we are: Speechmatics is the leading expert in Speech Intelligence, and uses AI and Machine Learning to unlock business value in human speech worldwide. We work with an amazing mix of global companies, and our technology can integrate into our customers stack irrespective of their industry or use case – making it the go-to solution to harness useful information from speech. Joining us means working with some of the smartest minds around the world, focused on cutting-edge projects and deploying the latest techniques to disrupt the market. We believe in putting people first; we’ll do all we can to help you develop your skills and give you the tools you need to thrive. Our Focus Fridays give you an undisturbed day of focus, offset with Together Tuesdays when we have our team meetings, so you've always got the right balance. We have structured a hybrid approach that includes 2-3 designated office days each week. This arrangement ensures that while we embrace the advantages of remote work, we also maintain the vital connection and synergy that only in-person interactions can foster. This is only the beginning; we’re looking for amazing people like you to continue our journey… What we can offer you: No matter what stage of your career you’re at - from paid internships and first-job opportunities through to management and senior positions - we’ll support you with the training and development needed to reach your career aspirations with us. There really is no shortage of opportunities here for you to get involved and collaborate with those around you to deliver your best work. We offer incredibly flexible working, regular company lunches, and birthday celebrations. But that’s not all. We’ve spoken to our teams to find out what they want. From Private Medical, and Dental for you and your family, through to global working opportunities, a generous holiday allowance and pension/401K matching, we want to make sure our employees and their families are looked after. Every employee will receive a working from home allowance for tech or home office equipment (on top of your choice of laptop and accessories of course). Our approach to parental leave is designed to support employees globally. While this varies by geo, we have support in place for parents (including adoption assistance and reproductive health s",https://aijobs.ai/job/staff-machine-learning-engineer-444
Senior Software Engineer I,Momentive,Canada - Remote,Hybrid,Senior,3000.0,8000.0,5500.0,"AWS, Python, Terraform","SurveyMonkey is the world’s most popular platform for surveys and forms, built for business—loved by users. We combine powerful capabilities with intuitive design, effectively serving every use case, from customer experience to employee engagement, market research to payment and registration forms. With built-in research expertise and AI-powered technology, it’s like having a team of expert researchers at your fingertips. Trusted by millions—from startups to Fortune 500 companies—SurveyMonkey helps teams gather insights and information that inspire better decisions, create experiences people love, and drive business growth. Discover how at surveymonkey.com . What we’re looking for Join our dynamic Cloud Engineering team and help shape the future of secure, scalable, and reliable cloud infrastructure. As a Cloud Engineer, you’ll play a critical role in designing, operating, and optimizing our AWS environments to meet the highest standards of performance and security. What you’ll be working on Operate and optimize AWS environments following best practices for security, reliability, and scalability. Collaborate with development teams to align cloud strategies with business objectives. Implement and maintain security frameworks (SOC 2, ISO 27001, PCI DSS 4.0) across cloud infrastructure. Automate deployments and configurations using Infrastructure as Code (IaC) tools like Terraform. Monitor and troubleshoot cloud systems, ensuring high availability and compliance. Enhance network architecture leveraging AWS networking services (Transit Gateway, VPC, Route 53, WAF, VPN). Identify vulnerabilities and apply preventive measures to maintain a secure environment. Participate in on-call rotation for critical support. We’d love to hear from people with 3-8 years of hands-on AWS experience, including IAM, VPC, EC2, ALB, S3, Lambda, CloudWatch, CloudFront, and CloudFormation. Strong knowledge of AWS networking (Transit Gateway, VPC, Route 53, Shield, WAF, Firewall Manager). Expertise in Infrastructure as Code (Terraform) and managing large-scale deployments. Proficiency in Linux/Windows administration and automation scripting. Experience with Python in DevOps or engineering contexts. Familiarity with security best practices and compliance standards SurveyMonkey believes in-person collaboration is valuable for building relationships, fostering community, and enhancing our speed and execution. While this role is remote, it may require in-person participation. You will be encouraged to attend company events throughout the year. These events will take place at a designated SurveyMonkey office or location. #LI-remote Why SurveyMonkey? We’re glad you asked At SurveyMonkey, curiosity powers everything we do. We’re a global company where people from all backgrounds can make an impact, build meaningful connections, and grow their careers. Our teams work in a flexible, hybrid environment with thoughtfully designed offices and programs like the CHOICE Fund to help employees thrive in work and life. We’ve been trusted by organizations for over 25 years, and we’re just getting started. Our milestones include celebrating a quarter-century of curiosity with 25 acts of giving , opening new hubs in Costa Rica and India , crossing the threshold of 100 billion questions answered , and earning recognition as one of the Most Inspiring Workplaces across North America and Asia . We live our company values —like championing inclusion and making it happen—by embedding them into how we hire, collaborate, and grow. They help shape everything from our culture to our business decisions. Come join us and see where your curiosity can take you. Our commitment to an inclusive workplace SurveyMonkey is an equal opportunity employer committed to providing a workplace free from harassment and discrimination. We celebrate the unique differences of our employees because that is what drives curiosity, innovation, and the success of our business. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, gender identity or expression, age, marital status, veteran status, disability status, pregnancy, parental status, genetic information, political affiliation, or any other status protected by the laws or regulations in the locations where we operate. Accommodations are available for applicants with disabilities.",https://aijobs.ai/job/senior-software-engineer-i-3
LLM Inference Performance & Evals Engineer,Cerebras Systems,"Toronto,  Ontario,  Canada",Non spécifié,Lead/Principal,,,,"Python, Machine Learning","Cerebras Systems builds the world's largest AI chip, 56 times larger than GPUs. Our novel wafer-scale architecture provides the AI compute power of dozens of GPUs on a single chip, with the programming simplicity of a single device. This approach allows Cerebras to deliver industry-leading training and inference speeds and empowers machine learning users to effortlessly run large-scale ML applications, without the hassle of managing hundreds of GPUs or TPUs. Cerebras' current customers include global corporations across multiple industries, national labs, and top-tier healthcare systems. In January, we announced a multi-year, multi-million-dollar partnership with Mayo Clinic, underscoring our commitment to transforming AI applications across various fields. In August, we launched Cerebras Inference, the fastest Generative AI inference solution in the world, over 10 times faster than GPU-based hyperscale cloud inference services. About The Role Join the inference model team dedicated to bring up the state-of-the-art models, numerically validating and accelerating new model ideas on wafer-scale hardware. You will prototype architectural tweaks, build performance-eval pipelines, and turn hard numbers into changes that land in production. Key Responsibilities Prototype and benchmark cutting-edge ideas: new attentions, MoE, speculative decoding, and many more innovations as they emerge. Develop agent-driven automation that designs experiments, schedules runs, triages regressions, and drafts pull-requests. Work closely with compiler, runtime, and silicon teams: unique opportunity to experience the full stack of software/hardware innovation. Keep pace with the latest open- and closed-source models; run them first on wafer scale to expose new optimization opportunities. Skills And Qualifications 3 + years building high-performance ML or systems software. Solid grounding in Transformer math—attention scaling, KV-cache, quantisation—or clear evidence you learn this material rapidly. Comfort navigating the full AI toolchain: Python modeling code, compiler IRs, performance profiling, etc. Strong debugging skills across performance, numerical accuracy, and runtime integration. Prior experience in modeling, compilers or crafting benchmarks or performance studies; not just black-box QA tests. Strong passion to leverage AI agents or workflow orchestration tools to boost personal productivity. Assets Hands-on with flash-attention, Triton kernels, linear-attention, or sparsity research. Performance-tuning experience on custom silicon, GPUs, or FPGAs. Proficiency in C/C++ programming and experience with low-level optimization. Proven experience in compiler development, particularly with LLVM and/or MLIR. Publications, repos, or blog posts dissecting model speed-ups. Contributions to open-source agent frameworks. Why Join Cerebras People who are serious about software make their own hardware. At Cerebras we have built a breakthrough architecture that is unlocking new opportunities for the AI industry. With dozens of model releases and rapid growth, we’ve reached an inflection  point in our business. Members of our team tell us there are five main reasons they joined Cerebras: Build a breakthrough AI platform beyond the constraints of the GPU. Publish and open source their cutting-edge AI research. Work on one of the fastest AI supercomputers in the world. Enjoy job stability with startup vitality. Our simple, non-corporate work culture that respects individual beliefs. Read our blog: Five Reasons to Join Cerebras in 2025. Apply today and become part of the forefront of groundbreaking advancements in AI! Cerebras Systems is committed to creating an equal and diverse environment and is proud to be an equal opportunity employer. We celebrate different backgrounds, perspectives, and skills. We believe inclusive teams build better products and companies. We try every day to build a work environment that empowers people to do their best work through continuous learning, growth and support of those around them. This website or its third-party tools process personal data. For more details, click here to review our CCPA disclosure notice.",https://aijobs.ai/job/llm-inference-performance-evals-engineer
Machine Learning Performance Engineer,Jane Street,"London,  England,  United Kingdom",Non spécifié,Non spécifié,,,,Machine Learning,"We are looking for an engineer with experience in low-level systems programming and optimisation to join our growing ML team. Machine learning is a critical pillar of Jane Street's global business. Our ever-evolving trading environment serves as a unique, rapid-feedback platform for ML experimentation, allowing us to incorporate new ideas with relatively little friction. Your part here is optimising the performance of our models – both training and inference. We care about efficient large-scale training, low-latency inference in real-time systems and high-throughput inference in research. Part of this is improving straightforward CUDA, but the interesting part needs a whole-systems approach, including storage systems, networking and host- and GPU-level considerations. Zooming in, we also want to ensure our platform makes sense even at the lowest level – is all that throughput actually goodput? Does loading that vector from the L2 cache really take that long? If you’ve never thought about a career in finance, you’re in good company. Many of us were in the same position before working here. If you have a curious mind and a passion for solving interesting problems, we have a feeling you’ll fit right in. There’s no fixed set of skills, but here are some of the things we’re looking for: An understanding of modern ML techniques and toolsets The experience and systems knowledge required to debug a training run’s performance end to end Low-level GPU knowledge of PTX, SASS, warps, cooperative groups, Tensor Cores and the memory hierarchy Debugging and optimisation experience using tools like CUDA GDB, NSight Systems, NSight Computesight-systems and nsight-compute Library knowledge of Triton, CUTLASS, CUB, Thrust, cuDNN and cuBLAS Intuition about the latency and throughput characteristics of CUDA graph launch, tensor core arithmetic, warp-level synchronization and asynchronous memory loads Background in Infiniband, RoCE, GPUDirect, PXN, rail optimisation and NVLink, and how to use these networking technologies to link up GPU clusters An understanding of the collective algorithms supporting distributed GPU training in NCCL or MPI An inventive approach and the willingness to ask hard questions about whether we're taking the right approaches and using the right tools Fluency in English If you're a recruiting agency and want to partner with us, please reach out to [email protected] .",https://aijobs.ai/job/machine-learning-performance-engineer-15
Sr. Machine Learning Engineer,PitchBook Data,"Seattle,  Washington,  United States",Remote,Senior,0.0,240000.0,120000.0,"Scikit-learn, Python, Java, Docker, Kubernetes, Kafka, Machine Learning, TensorFlow, PyTorch","At PitchBook, a Morningstar company, we are always looking forward. We continue to innovate, evolve, and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy, and fun that reverberates throughout the company. Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast, and do it all over again in the pursuit of excellence. If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you. About the Role: As a member of the Product and Engineering team at PitchBook, you will be part of a team of big thinkers, innovators, and problem solvers who strive to deepen the positive impact we have on our customers and our company every day. We value curiosity and the drive to find better ways of doing things. We thrive on customer empathy, which remains our focus when creating excellent customer experiences through product innovation. We know that greatness is achieved through collaboration and diverse points of view, so we work closely with partners around the globe. As a team, we assume positive intent in each other’s words and actions, value constructive discussions, and foster a respectful working environment built on integrity, growth, and business value. We invest heavily in our people, who are eager to learn and constantly improve. Join our team and grow with us! As a Senior Machine Learning Engineer (MLE) on the AI & ML (Insights) team, you will play a critical role in delivering AI-powered features that extract meaningful insights from PitchBook’s wealth of structured and unstructured data including reports, news, and other textual content. This role requires deep technical expertise in advanced data analytics and machine learning, as well as a hands-on approach to designing, building, and optimizing ML solutions that power user-facing features on the PitchBook Platform. You will be deeply involved in the end-to-end development and operationalization of ML models, including their architecture, training, deployment, and ongoing maintenance. Your focus will span across natural language processing (NLP), generative AI (GenAI), large language models (LLMs), and scalable data systems. You will be expected to tackle complex technical challenges, contribute to architectural decisions, and collaborate closely with other engineers, data scientists, and product managers to ensure that your work aligns with business goals and AI/ML strategy. Your contributions will help unlock unique value for PitchBook customers by improving the speed, discoverability, quality, and quantity of insights available on the platform. This includes developing models that can infer meaning and structure from millions of discrete data sources, and applying ML to enrich our datasets with predictive and generative intelligence. As a senior engineer, you will take ownership of key technical components and ensure that our systems meet the highest standards of performance, reliability, and security. Primary Job Responsibilities: Deliver high-impact AI and ML capabilities that drive insight generation on the PitchBook Platform. Ensure your work contributes to broader business goals and is aligned with the team's strategic priorities Provide hands-on expertise in designing, building, and deploying AI/ML models and services with a focus on NLP, summarization, semantic search, classification, and prediction. Contribute to the development of scalable, high-performance systems that meet production-grade reliability and efficiency standards Support a culture of technical excellence by mentoring peers, sharing knowledge, and participating in code and design reviews. Promote innovation and continuous improvement through collaborative engineering practices Build and optimize models that leverage classifiers, transformers, LLMs, and other NLP techniques to generate meaningful insights from structured and unstructured data. Integrate these models into the broader AI/ML infrastructure in collaboration with partner teams Collaborate with engineering, product management, and data collection teams to ensure models are informed by high-quality data and support strategic product goals Explore and experiment with emerging technologies, methodologies, and tools in the fields of GenAI, NLP, and search. Translate research findings into practical solutions that enhance PitchBook’s AI capabilities Contribute to best practices in model transparency, monitoring, evaluation, and compliance. Help maintain high standards of security, data integrity, and responsible AI use across your projects Participate in the technical evaluation of candida",https://aijobs.ai/job/sr-machine-learning-engineer
Senior Machine Learning Engineer,Speechmatics,"London,  England,  United Kingdom",Hybrid,Senior,2000.0,3000.0,2500.0,"Go, Machine Learning","We are hiring a Senior Machine Learning Engineer to contribute to cutting-edge Research & Development. As innovators in speech technology, our mission is to Understand Every Voice—a vision that has propelled us to be world leaders of Voice AI, consisting of STT, TTS, and Flow; our brand new Conversational AI platform. Fuelled by innovation, inclusivity, and a passion for making a global impact through world-leading Speech AI, we're looking for an experienced Machine Learning Engineer to accelerate our efforts towards exceptional speech solutions. Our Modelling Team trains diverse models, including large self-supervised ones, supporting Speechmatics towards being the most accurate speech recognition system globally. It also ensures their deployment into production, working with the latest developments in ML, but also with the best engineering practices for software engineering and model serving. What you’ll be doing: Work on complex R&D projects, with a diverse group of engineers, to achieve ambitious goals. Stay current with the latest developments in Machine learning. Execute high-impact projects to ensure team success. Work collaboratively across departments and mentor team members (where appropriate). Who we are looking for: Demonstrated experience in collaboratively pursuing ambitious R&D agendas. Precise attention to detail, but is also aware of how the big picture relates to company goals, and where the field of Machine Learning is headed towards. Understanding of the modern Machine Learning stack, for example: - Knowledge of contemporary transformer architectures (e.g., GQA, KV-caching) and best practices. - Experience in distributed training techniques. - Familiarity with optimisation strategies for model inference (e.g., dynamic batching, flash attention, speculative decoding). With preferred backgrounds covering some of the following: - Publications in top-tier conferences. - Contributions to popular open-source repositories. - Technical writing skills as evidenced by relevant publications or blogs. We encourage you to apply even if you do not feel you match all of the requirements exactly. The list of requirements is intended to show the kinds of experience and qualities we’re looking for, but it is not exhaustive. If you are interested in the role, the team, and our mission, we would love to consider your application. We are always open to conversations and look forward to hearing from you. Who we are: Speechmatics is the leading expert in Speech Intelligence, and uses AI and Machine Learning to unlock business value in human speech worldwide. We work with an amazing mix of global companies, and our technology can integrate into our customers stack irrespective of their industry or use case – making it the go-to solution to harness useful information from speech. Joining us means working with some of the smartest minds around the world, focused on cutting-edge projects and deploying the latest techniques to disrupt the market. We believe in putting people first; we’ll do all we can to help you develop your skills and give you the tools you need to thrive. Our Focus Fridays give you an undisturbed day of focus, offset with Together Tuesdays when we have our team meetings, so you've always got the right balance. We have structured a hybrid approach that includes 2-3 designated office days each week. This arrangement ensures that while we embrace the advantages of remote work, we also maintain the vital connection and synergy that only in-person interactions can foster. This is only the beginning; we’re looking for amazing people like you to continue our journey… What we can offer you: No matter what stage of your career you’re at - from paid internships and first-job opportunities through to management and senior positions - we’ll support you with the training and development needed to reach your career aspirations with us. There really is no shortage of opportunities here for you to get involved and collaborate with those around you to deliver your best work. We offer incredibly flexible working, regular company lunches, and birthday celebrations. But that’s not all. We’ve spoken to our teams to find out what they want. From Private Medical, and Dental for you and your family, through to global working opportunities, a generous holiday allowance and pension/401K matching, we want to make sure our employees and their families are looked after. Every employee will receive a working from home allowance for tech or home office equipment (on top of your choice of laptop and accessories of course). Our approach to parental leave is designed to support employees globally. While this varies by geo, we have support in place for parents (including adoption assistance and reproductive health services) to ensure they have the time and financial resources needed to care for their growing families. At Speechmatics, our mission is simple: Understand Every Voice out there. That's not just about our tech – it's t",https://aijobs.ai/job/senior-machine-learning-engineer-1773
"Senior Software Engineer, ML Platform",PlayStation Global,"United States,  San Diego,  CA",Remote,Senior,300000.0,241000.0,270500.0,"AWS, Python, Java, Kafka, Machine Learning","Why PlayStation? PlayStation isn’t just the Best Place to Play — it’s also the Best Place to Work. Today, we’re recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation®5, PlayStation®4, PlayStation®VR, PlayStation®Plus, acclaimed PlayStation software titles from PlayStation Studios, and more. PlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Group Corporation. Senior Software Engineer, ML Platform United States, Remote; United States, San Diego, CA; United States, San Mateo, CA Why PlayStation? PlayStation isn’t just the Best Place to Play — it’s also the Best Place to Work. Today, we’re recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation®5, PlayStation®4, PlayStation®VR, PlayStation®Plus, acclaimed PlayStation software titles from PlayStation Studios, and more. PlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team. The PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Group Corporation. Senior Software Engineer, ML Platform - D2C - SPOC Sony Interactive Entertainment (SIE) PlayStation | San Diego, CA Who We Are At Sony Interactive Entertainment (SIE) PlayStation, we create unforgettable gaming experiences—and we’re equally dedicated to building a world-class team. As a leader in interactive entertainment, PlayStation operates at massive scale, supporting millions of players worldwide and processing billions of transactions annually across our digital ecosystem. Our Store Publishing Operations & Commerce (SPOC) team is responsible for ensuring trust, security, and seamless transactions across PlayStation’s digital store. We provide data-driven solutions to support platform services, customer experience, payments, fraud prevention, and risk management. Using advanced analytics and machine learning/AI, we help protect the commerce ecosystem, facilitate business growth, and optimize player experiences. About the Role This position is a hands-on engineering role with a broad range of responsibilities, from evolving and supporting real-time †machine learning/AI pipelines to building low-latency, high-throughput systems. You should be well-versed in running applications at internet scale on modern cloud architectures (e.g., AWS). If you’re a software engineer with a strong interest in large-scale machine learning projects, experimentation, automation, or real-time risk mitigation, we’d love to connect with you. Key Responsibilities Create Cloud Solutions : Design and implement cloud solutions using AWS to ensure high performance, scalability, and reliability. ML/AI Pipeline : Build and enhance ML/AI pipelines in partnership with Data Science to support automation, experimentation, continuous integration/delivery, verification/validation, and model monitoring. Core Infrastructure Development : Develop and maintain core infrastructure for data streaming and processing, applying industry standards and innovative solutions. Service Availability : Guarantee high levels of service availability through being a part of an on-call rotation, following best practices for disaster recovery and business continuity. Qualifications and Education Requirements Educational Background : Bachelor’s degree with 5+ years of related experience Coding Proficiency : Demonstrated experience building reliable software with Java or/and Python Cloud Competency : Proficiency with common AWS services (EKS/ECS, Kinesis, Lambda, DynamoDB) or their cloud equivalent. Systems Monitoring and Analytics : Experience with systems monitoring, alerting, and analytics tools like Datadog, Splunk, or AWS CloudTrail Communication Skills : Strong communication skills to collaborate with multi-functional teams Preferred Skills Streaming or SQL at scale : Hands-on with high-volume event pipelines (Kinesis/Kafka/ActiveMQ) and/or SQL over large datasets. Data Science & Machine Learning : Exposure to Data Science and Machine Learning We sincerely appreciate the time and effort you’ve spent in contacting us, and we thank you for your interest in PlayStation. Please refer to our Candidate Privacy Notice for more information about how we process your personal information, and your data protection rights. At SIE, we consider several factors when setting each role’s base pay range, including the competitive benchmarking data for the market and ge",https://aijobs.ai/job/senior-software-engineer-ml-platform
Senior Embedded SW/FW Engineer (Bringup),Graphcore,"Austin,  Texas,  United States",Hybrid,Senior,500000.0,211000.0,355500.0,Python,"Senior Embedded SW/FW Engineer (Bringup) Salary $156,500 - $211,700 + Phantom Equity + Benefits Graphcore is a globally recognised leader in Artificial Intelligence computing systems. The company designs advanced semiconductors and data centre hardware that provide the specialised processing power needed to drive AI innovation, while delivering the efficiency required to support its broader adoption. As part of the SoftBank Group, Graphcore is a member of an elite family of companies responsible for some of the world’s most transformative technologies. We are opening a new AI Engineering Campus in Austin which will play a central role in Graphcore's work building the future of AI computing. We are looking to hire Post-Silicon Validation Engineers to join our collaborative, cross-functional development team validating cutting edge, high performance AI chips and platforms. You will play a critical role in supporting new product introductions and post-silicon validation. Working within the Post-Silicon Validation team, you will be involved with bringing first silicon to life, functionally validating it and working closely with many other teams to help it become a fully characterised and working product, reporting project status/progress to program management on a regular basis. You will have the opportunity to, and be responsible for, leading, mentoring, and providing technical guidance to other engineering team members. In this role, you can leverage your experience and industry knowledge to architect and drive implementation of continuous improvements to test infrastructure and processes. The Post-Silicon Validation team sits within the Architecture and Validation team, we are responsible for validation of new silicon when it returns from manufacture, enabling and supporting the production SW and FW teams to bring up their software and also supporting the Silicon Characterisation team. Responsibilities and Duties Plan, design, develop and debug silicon validation tests in bare metal C/C++ on FPGA/Emulator prior to first silicon Deploy silicon validation tests on first silicon and debugging them Develop automated test framework and regression test suites in Python to optimize validation efficiency Collaborate closely with engineers from many other disciplines on a variety of topics Work with Validation and Production Test engineering peers to implement best practices and continuous improvements to test methodologies Analyse test results, identify and debug failures/defects Contribute to shared test and validation infrastructure Provide feedback to architects Essential skills: Strong experience in Bare metal / embedded C/C++ Good knowledge of digital ASICs Be highly motivated, a self starter, and a team player Ability to work across teams and programming languages to find root causes of deep and complex issues Experience of the post-silicon validation process applied in digital ASIC environments Python, Linux Excellent communication skills and the ability to collaborate with others to solve problems Excellent problem-solving, analytical & diagnostic skills Desirable skills: Driver level experience with one or more of the following is highly desirable: PCIe Ethernet Memory technologies (LPDDR, DDR, HBM, …) Other peripherals such as I2C, I3C, SPI, … Good knowledge of mixed-signal building blocks such as PLLs, high speed PHYs and IC control/communication protocols is highly desirable Experience of Arm CPUs , System IP and debug tools Experience of AMBA protocols Understanding of ML applications and their workloads Experience in Characterization, Failure Analysis, Test Development, Statistical analysis, and Customer Support Benefits: In addition to a competitive salary, Graphcore offers a competitive benefits package. We welcome people of different backgrounds and experiences; we’re committed to building an inclusive work environment that makes Graphcore a great home for everyone. We offer an equal opportunity process and understand that there are visible and invisible differences in all of us. We can provide a flexible approach to interview and encourage you to chat to us if you require any reasonable adjustments.",https://aijobs.ai/job/senior-embedded-swfw-engineer-bringup
Forward Deployed Engineer - New Jersey,CommerceIQ,"Hoboken,  New Jersey,  United States",On-site,Senior,4000.0,6000.0,5000.0,"Python, Java","Company Overview CommerceIQ’s AI-powered digital commerce platform is revolutionizing the way brands sell online. Our unified ecommerce management solutions empower brands to make smarter, faster decisions through insights that optimize the digital shelf, increase retail media ROI and fuel incremental sales across the world’s largest marketplaces. With a global network of more than 900 retailers, our end-to-end platform helps 2,200+ of the world’s leading brands streamline marketing, supply chain, and sales operations to profitably grow market share in more than 50 countries. 10 out of the top 12 CPG brands work with us, including Coca-Cola, Nestle, Colgate-Palmolive, and Mondelez. We’ve raised over $200M from some of the top investors including SoftBank, Insight Partners, and Madrona. Learn more at commerceiq.ai . The Role: As a Forward Deployed Engineer , you will partner closely with our founders and the AI Product Managers to prototype and deploy AI‑driven solutions that solve our customers’ most pressing problems. This is a founding engineering role with high visibility; you will report directly to our Head of AI Strategy and Outcomes. You will also partner with other members of the executive leadership team who are based at our Mountain View HQ, collaborate with our Bangalore‑based engineering team, and engage daily with enterprise customers. You will help define how we work with our most important customers, shape the company’s first ever forward deployed engineering function, and contribute to our mission of helping brands win in AI‑driven e-commerce. Location / Travel: This position is on-site in Hoboken, New Jersey with approximately 50% travel expected to client locations. We are only considering candidates located in the tri-state area at this time. What You'll Do: Build prototypes with customers: Work alongside our AI Product Manager to understand real‑world problems, rapidly scope use cases and create working prototypes. You’ll engage in hands-on discovery and convert insights into functional demos for prospective and existing customers. Integrate data and create new AI agents: Ingest data from disparate sources (ERPs, ecommerce platforms, custom APIs) and build agents that solve the specific use cases uncovered during discovery. This includes turning edge‑case business rules into runtime‑editable settings rather than hard‑coded logic. Own AI outcomes: Lead customer‑facing demonstrations and proof‑of‑concepts. You’ll instrument and tune models using production feedback loops to ensure prototypes deliver measurable outcomes. Rapidly iterate & generalize: Collaborate with engineering teams in Bangalore to transform prototypes into robust features. Your work will be implemented into our core product - patterns that succeed in one deployment (custom adapters, monitoring dashboards) should be packaged as reusable modules. Own the full lifecycle: Support engagements from pre‑sales scoping through post‑deployment refinement. You’ll help to negotiate scope, push back on unreasonable asks, and ensure long‑term customer success. Additionally, you’ll act as the technical liaison between customers, product managers, and engineering. Cultivate customer relationships: Develop deep empathy for our customers’ business drivers and serve as their advocate. Use clear, engaging communication to convey technical concepts to non‑technical stakeholders, build trust and handle high‑stakes conversations. What You'll Bring: Experienced engineer (4-6 years or more) with a strong foundation in software development (data structures, system design, debugging). Comfortable coding in Python or Java and learning new technologies quickly. Full‑stack & data integration skills. Experience connecting to APIs, working with SQL/NoSQL databases, streaming/ETL pipelines and deploying AI/LLM‑based agents. Customer‑facing problem solver. You enjoy working directly with external users, conducting discovery, and translating ambiguous requirements into working solutions. You have excellent communication skills and the ability to simplify complex technical topics. Rapid prototyper. You are biased towards action and are comfortable delivering minimal‑viable solutions, collecting feedback and iterating quickly. Collaborative & global. You’re effective working across time zones with leadership in California and engineering in Bangalore. You embrace CommerceIQ’s leadership principles of ownership, deep diving into details, getting stuff done, thinking from first principles and winning as a team. Independent & adaptable. You thrive in ambiguity, can manage your own backlog and priorities, and are motivated by the opportunity to create a new function. Bachelor's degree, in Computer Science, Mathematics, or a related field Nice to Haves: Prior experience in a forward‑deployed, solutions engineering or customer implementation role. Candidates coming from companies known for forward‑deployed engineering (e.g., Palantir, Scale AI, Ramp, etc.) are st",https://aijobs.ai/job/forward-deployed-engineer-new-jersey
Senior Runtime Performance Engineer,Cerebras Systems,"Toronto,  Ontario,  Canada",Non spécifié,Senior,,,,"Python, Machine Learning, PyTorch","Cerebras Systems builds the world's largest AI chip, 56 times larger than GPUs. Our novel wafer-scale architecture provides the AI compute power of dozens of GPUs on a single chip, with the programming simplicity of a single device. This approach allows Cerebras to deliver industry-leading training and inference speeds and empowers machine learning users to effortlessly run large-scale ML applications, without the hassle of managing hundreds of GPUs or TPUs. Cerebras' current customers include global corporations across multiple industries, national labs, and top-tier healthcare systems. In January, we announced a multi-year, multi-million-dollar partnership with Mayo Clinic, underscoring our commitment to transforming AI applications across various fields. In August, we launched Cerebras Inference, the fastest Generative AI inference solution in the world, over 10 times faster than GPU-based hyperscale cloud inference services. About the Role Join Cerebras as a Performance Engineer within our innovative Runtime Team. Our groundbreaking CS-3 system, hosted by a distributed set of modern and powerful x86 machines, has set new benchmarks in high-performance ML training and inference solutions. It leverages a dinner-plate sized chip with 44GB of on-chip memory to surpass traditional hardware capabilities. This role will challenge and expand your expertise in optimizing AI applications and managing computational workloads primarily on the x86 architecture that run our Runtime driver. Responsibilities Focus on CPU and memory subsystem optimizations for our Runtime software driver, enabling faster key cloud and ML training/inference workloads across modern x86 machines that form the backbone of our AI accelerator. Develop and enhance algorithms for efficient data movement, local data processing, job submission, and synchronization between various software and hardware components. Optimize our workloads using advanced CPU features like AVX instructions, prefetch mechanisms, and cache optimization techniques. Perform performance profiling and characterization using tools such as AMD uprof, and reduce OS level overheads. Influence the design of Cerebras' next-generation AI architectures and software stack by analyzing the integration of advanced CPU features and their impact on system performance and computational efficiency. Engage directly with the AI and ML developer community to understand their needs and solve contemporary challenges with innovative solutions. Collaborate with multiple teams within Cerebras, including architecture, research, and product management, to elevate our computational platform and influence future designs. Skills And Qualifications BS, MS, or PhD in Computer Science, Computer Engineering, or a related field. 5+ years of relevant experience in performance engineering, particularly in optimizing algorithms and software design. Strong proficiency in C/C++ and familiarity with Python or other scripting languages. Demonstrated experience with memory subsystem optimizations and system-level performance tuning. Experience with distributed systems is highly desirable, as it is crucial to optimizing the performance of our Runtime software across multiple x86 hosts. Familiarity with compiler technologies (e.g., LLVM, MLIR) and with PyTorch and other ML frameworks. Why Join Cerebras People who are serious about software make their own hardware. At Cerebras we have built a breakthrough architecture that is unlocking new opportunities for the AI industry. With dozens of model releases and rapid growth, we’ve reached an inflection  point in our business. Members of our team tell us there are five main reasons they joined Cerebras: Build a breakthrough AI platform beyond the constraints of the GPU. Publish and open source their cutting-edge AI research. Work on one of the fastest AI supercomputers in the world. Enjoy job stability with startup vitality. Our simple, non-corporate work culture that respects individual beliefs. Read our blog: Five Reasons to Join Cerebras in 2025. Apply today and become part of the forefront of groundbreaking advancements in AI! Cerebras Systems is committed to creating an equal and diverse environment and is proud to be an equal opportunity employer. We celebrate different backgrounds, perspectives, and skills. We believe inclusive teams build better products and companies. We try every day to build a work environment that empowers people to do their best work through continuous learning, growth and support of those around them. This website or its third-party tools process personal data. For more details, click here to review our CCPA disclosure notice.",https://aijobs.ai/job/senior-runtime-performance-engineer
Senior Software Engineer - AI,NetDocuments,"Lehi,  Utah,  United States; Remote - US",Hybrid,Junior,0.0,165000.0,82500.0,"Azure, AWS, Microservices, React, Docker, Kubernetes","NetDocuments is committed to providing an excellent candidate experience and will never ask you to engage in recruitment activity without phone, video, and in person meetings and communications from emails using the @netdocuments.com domain. If you have any concerns or questions about communications you have received, please send them to [email protected] m so our team members can review. NetDocuments is the world’s #1 trusted cloud-based content management and productivity platform that helps legal professionals do their best work. We strive to win together through passionate hard work, exploring new things and recognizing every interaction matters. NetDocuments provides rewarding career growth in an inclusive, diverse environment where employees are encouraged to openly contribute creative ideas and innovation, backed by supportive peers and leadership working together to achieve our goals as a unified team. At our core, we are dedicated to empowering our employees to drive successful business outcomes and better user experiences for our customers and partners. Our customer-centric approach and employee enablement has allowed us to enjoy many accolades, including being named among the 2022,  2023, & 2024 list of Inc. Magazine’s 5000 Fastest-Growing Private Companies in America. Other recent awards include: Two-time winner (2024, 2023) National Top Workplaces Two-time winner (2024, 2023) Top Workplace innovation Three-time winner (2023, 2022, 2021) Top Workplace in the US by the Salt Lake Tribune Three-time winner (2023, 2022, 2021) Best Companies to Work for by Utah Business magazine Three-time winner (2024, 2023, 2022) Top Workplace Work-Life Flexibility Three-time winner (2024, 2023, 2022) Top Workplace Compensation & Benefits 2024 Cultural Excellence 2024 Technology Industry 2023 Top Workplace Leadership 2023 Top Workplace Purpose & Values 2022 Top Workplace Employee Appreciation and Employee Well Being NetDocuments is a hybrid, remote-friendly workplace. Come join our team and work inspired each day! What You’ll Do We're looking for a Senior Software Engineer with a passion for building robust backend systems and scalable cloud solutions. You'll contribute to the development of cutting-edge, AI-powered products that elevate the way our clients work—delivering both behind-the-scenes functionality and seamless user-facing experiences. As a key member of a modern engineering team, you’ll help design and implement high-performing microservices and cloud-native applications that support our evolving PaaS offerings. You’ll play an important role in enhancing the reliability, scalability, and performance of our software platforms. This role reports to the Manager, Software Engineering and offers the opportunity to build innovative systems while collaborating closely with experienced engineers and cross-functional teams. You will: Design and Develop Scalable Systems Contribute to the design and architecture of a large-scale system centered around search capabilities Build and maintain applications and services using technologies like React, C#, microservices, AWS, Azure and others as appropriate Implement scalable and secure cloud-native solutions aligned with performance and reliability best practices Extend and optimize existing applications with minimal supervision Translate functional requirements into robust technical solutions Testing, Deployment & Optimization Conduct unit and integration testing across different environments Monitor performance, troubleshoot issues, and optimize system behavior Participate in the creation and refinement of system specifications, standards, and guidelines Collaboration & Teamwork Collaborate with product managers, designers, and other engineers to plan and deliver features Contribute to a strong team culture through code reviews, design sessions, and shared learning Provide informal mentoring to junior developers and share best practices Continuous Learning & Improvement Stay current with modern engineering tools, practices, and frameworks Evaluate and recommend process or tooling improvements to increase development efficiency Contribute to maintaining a secure, performant, and maintainable codebase What You’ll Need to be Successful Bachelor’s degree in Computer Science , Information Systems, or a related field—or equivalent experience 5+ years of full-stack development experience, ideally with some exposure to cloud platforms Experience working within agile development teams and delivering high-quality software Familiarity with mentoring peers or onboarding new developers a plus, though not a primary focus Required Knowledge: React C# / .Net Microservices Public cloud experience (AWS or Azure) Frontend state management (e.g., Redux) RESTful APIs and backend platform experience Kubernetes CosmosDB or DynamoDB What Will Make You Stand Out AI/ML project experience or interest in applying AI to real-world applications Familiarity with Docker Exposure to backend-for-front",https://aijobs.ai/job/senior-software-engineer-ai-131
Frontend Engineer,Lightning AI,"London,  England,  United Kingdom",Hybrid,Lead/Principal,,,,"JavaScript, TypeScript, React, PyTorch","Who We Are Lightning AI is the company reimagining the way AI is built. After creating and releasing PyTorch Lightning in 2019, Lightning AI was launched to reshape the development of artificial intelligence products for commercial and academic use. We are on a mission to simplify AI development, making it accessible to everyone—from solo researchers to large enterprises. By removing the complexity of building and deploying AI tools, we empower innovators to focus on solving real-world problems. Our platform is built to scale with the latest AI advancements while staying intuitive and adaptable, so you can bring your ideas to life. We have offices in New York City, San Francisco, and London and are backed by investors such as Coatue, Index Ventures, Bain Capital Ventures, and Firstminute. Our Values Move Fast : We act with speed and precision, breaking down big challenges into achievable steps. Focus : We complete one goal at a time with care, collaborating as a team to deliver features with precision. Balance : Sustained performance comes from rest and recovery. We ensure a healthy work-life balance to keep you at your best. Craftsmanship : Innovation through excellence. Every detail matters, and we take pride in mastering our craft. Minimal : Simplicity drives our innovation. We eliminate complexity through discipline and focus on what truly matters. What We're Looking For We are looking for a frontend engineer to help us develop and scale the UI and frontend infrastructure of the Lightning AI platform. We want someone who can take ownership of key features and drive development from end to end while collaborating with a super-smart team of engineers, product managers, and designers. Here, you’ll build from proof of concept to release with a focus on speed, quality, and iteration. With over 10,000 organizations building with Lightning, you’ll have a unique opportunity to impact how the world builds and deploys AI to production. You will be joining the Growth Squad and report to our Director of Engineering. This is a hybrid role based in our London office with in-office requirements of 2 days per week. What You’ll Do Write readable/testable/efficient code in React and Redux and master our technology stack to deliver new features, improve system stability, and increase overall performance. Partner with engineering and product leaders on developing the user interface and frontend infrastructure while using your experience to set the technical direction for large projects. Evaluate, strengthen, and document technical architecture, tools, and processes. Champion software quality, implement automation, drive continuous delivery, and reduce time to production while proactively reducing technical debt. Mentor and coach engineers on system design, operating in high uncertainty, and problem-solving to create a supportive, inclusive environment in which each engineer can grow. What You’ll Need Proficiency in React, javascript and typescript. Strong understanding of software engineering principles and lifecycle. Hands-on experience as a frontend engineer in a SaaS technology company Proven ability to take ownership of key features and drive end-to-end development Communication and collaboration with engineers, product managers, and designers Ability to operate in high uncertainty and rapidly changing environments Benefits and Perks We offer competitive base salaries and stock options with a 25% one year cliff and monthly vesting thereafter. For our international employees, we work with Velocity Global to pay you in your local currency and provide equitable benefits across the globe. In the US, we offer: Medical, dental and vision Life and AD&D insurance Flexible paid time off plus 1 week of winter closure Generous paid family leave benefits $500 monthly meal reimbursement, including groceries & food delivery services $500 one time home office stipend $1,000 annual learning & development stipend 100% Citibike membership (NYC only) $45/month gym membership Additional various medical and mental health services At Lightning AI, we are committed to fostering an inclusive and diverse workplace. We believe that diverse teams drive innovation and create better products. We provide equal employment opportunities to all employees and applicants without regard to race, color, religion, gender, sexual orientation, gender identity, national origin, age, disability, veteran status, or any other protected characteristic. We are dedicated to building a culture where everyone can thrive and contribute to their fullest potential.",https://aijobs.ai/job/frontend-engineer-114
Full Stack LLM Engineer,Cerebras Systems,"Toronto,  Ontario,  Canada",Non spécifié,Senior,,,,"Python, Machine Learning, TensorFlow, PyTorch","Cerebras Systems builds the world's largest AI chip, 56 times larger than GPUs. Our novel wafer-scale architecture provides the AI compute power of dozens of GPUs on a single chip, with the programming simplicity of a single device. This approach allows Cerebras to deliver industry-leading training and inference speeds and empowers machine learning users to effortlessly run large-scale ML applications, without the hassle of managing hundreds of GPUs or TPUs. Cerebras' current customers include global corporations across multiple industries, national labs, and top-tier healthcare systems. In January, we announced a multi-year, multi-million-dollar partnership with Mayo Clinic, underscoring our commitment to transforming AI applications across various fields. In August, we launched Cerebras Inference, the fastest Generative AI inference solution in the world, over 10 times faster than GPU-based hyperscale cloud inference services. About the Role We are seeking a versatile and experienced engineer to join our Inference Core Model Bringup team. This team is responsible to rapidly bring up state-of-the-art open-source models (like LLaMA, Qwen, etc) or customer-provided proprietary models on our Cerebras CSX systems. Success in this role requires a system-minded generalist who thrives in fast-paced bringup environments and is comfortable working across the entire Cerebras software stack. Your work will play a critical role in achieving unprecedented levels of performance, efficiency, and scalability for AI applications. Responsibilities Contribute to the end-to-end bring up of ML models on Cerebras CSX systems. Work across the stack: model architecture translation, graph lowering, compiler optimizations, runtime integration, and performance tuning. Debug performance and correctness issues spanning model code, compiler IRs, runtime behavior, and hardware utilization. Propose and prototype improvements across tools, APIs, or automation flows to accelerate future bring ups. Skills & Qualifications Bachelor’s, Master’s, or PhD in Computer Science, Engineering, or a related field. Comfort navigating the full AI toolchain: Python modeling code, compiler IRs, performance profiling, etc. Strong debugging skills across performance, numerical accuracy, and runtime integration. Experience with deep learning frameworks (e.g., PyTorch, TensorFlow) and familiarity with model internals (e.g., attention, MoE, diffusion). Proficiency in C/C++ programming and experience with low-level optimization. Proven experience in compiler development, particularly with LLVM and/or MLIR. Strong background in optimization techniques, particularly those involving NP-hard problems. What We Offer Competitive salary and benefits package. Opportunities for professional growth and career advancement. A dynamic and innovative work environment. The chance to work on cutting-edge technologies and make a significant impact on the future of AI. Why Join Cerebras People who are serious about software make their own hardware. At Cerebras we have built a breakthrough architecture that is unlocking new opportunities for the AI industry. With dozens of model releases and rapid growth, we’ve reached an inflection  point in our business. Members of our team tell us there are five main reasons they joined Cerebras: Build a breakthrough AI platform beyond the constraints of the GPU. Publish and open source their cutting-edge AI research. Work on one of the fastest AI supercomputers in the world. Enjoy job stability with startup vitality. Our simple, non-corporate work culture that respects individual beliefs. Read our blog: Five Reasons to Join Cerebras in 2025. Apply today and become part of the forefront of groundbreaking advancements in AI! Cerebras Systems is committed to creating an equal and diverse environment and is proud to be an equal opportunity employer. We celebrate different backgrounds, perspectives, and skills. We believe inclusive teams build better products and companies. We try every day to build a work environment that empowers people to do their best work through continuous learning, growth and support of those around them. This website or its third-party tools process personal data. For more details, click here to review our CCPA disclosure notice.",https://aijobs.ai/job/full-stack-llm-engineer
Principal Post Silicon Validation Engineer (Bringup),Graphcore,"Austin,  Texas,  United States",Hybrid,Lead/Principal,100000.0,326000.0,213000.0,Python,"Principal Post Silicon Validation Engineer (Bringup) Salary $241,100 - $326,100 + Phantom Equity + Benefits Graphcore is a globally recognised leader in Artificial Intelligence computing systems. The company designs advanced semiconductors and data centre hardware that provide the specialised processing power needed to drive AI innovation, while delivering the efficiency required to support its broader adoption. As part of the SoftBank Group, Graphcore is a member of an elite family of companies responsible for some of the world’s most transformative technologies. We are opening a new AI Engineering Campus in Austin which will play a central role in Graphcore's work building the future of AI computing. We are looking to hire Post-Silicon Validation Engineers to join our collaborative, cross-functional development team validating cutting edge, high performance AI chips and platforms. You will play a critical role in supporting new product introductions and post-silicon validation. Working within the Post-Silicon Validation team, you will be involved with bringing first silicon to life, functionally validating it and working closely with many other teams to help it become a fully characterised and working product, reporting project status/progress to program management on a regular basis. You will have the opportunity to, and be responsible for, leading, mentoring, and providing technical guidance to other engineering team members. In this role, you can leverage your experience and industry knowledge to architect and drive implementation of continuous improvements to test infrastructure and processes. The Post-Silicon Validation team sits within the Architecture and Validation team, we are responsible for validation of new silicon when it returns from manufacture, enabling and supporting the production SW and FW teams to bring up their software and also supporting the Silicon Characterisation team. Responsibilities and Duties Plan, design, develop and debug silicon validation tests in bare metal C/C++ on FPGA/Emulator prior to first silicon Deploy silicon validation tests on first silicon and debugging them Develop automated test framework and regression test suites in Python to optimize validation efficiency Collaborate closely with engineers from many other disciplines on a variety of topics Work with Validation and Production Test engineering peers to implement best practices and continuous improvements to test methodologies Analyse test results, identify and debug failures/defects Contribute to shared test and validation infrastructure Provide feedback to architects Essential skills: Strong experience in Bare metal / embedded C/C++ Good knowledge of digital ASICs Be highly motivated, a self starter, and a team player Ability to work across teams and programming languages to find root causes of deep and complex issues Experience of the post-silicon validation process applied in digital ASIC environments Python, Linux Excellent communication skills and the ability to collaborate with others to solve problems Excellent problem-solving, analytical & diagnostic skills Desirable skills: Driver level experience with one or more of the following is highly desirable: PCIe Ethernet Memory technologies (LPDDR, DDR, HBM, …) Other peripherals such as I2C, I3C, SPI, … Good knowledge of mixed-signal building blocks such as PLLs, high speed PHYs and IC control/communication protocols is highly desirable Experience of Arm CPUs , System IP and debug tools Experience of AMBA protocols Understanding of ML applications and their workloads Experience in Characterization, Failure Analysis, Test Development, Statistical analysis, and Customer Support Benefits: In addition to a competitive salary, Graphcore offers a competitive benefits package. We welcome people of different backgrounds and experiences; we’re committed to building an inclusive work environment that makes Graphcore a great home for everyone. We offer an equal opportunity process and understand that there are visible and invisible differences in all of us. We can provide a flexible approach to interview and encourage you to chat to us if you require any reasonable adjustments.",https://aijobs.ai/job/principal-post-silicon-validation-engineer-bringup
Director of Engineering - Platform Services,Momentive,"Canada - Remote; Ottawa,  Canada",Hybrid,Senior,,,,"Azure, AWS, Microservices, CI/CD, Terraform, GCP","SurveyMonkey is the world’s most popular platform for surveys and forms, built for business—loved by users. We combine powerful capabilities with intuitive design, effectively serving every use case, from customer experience to employee engagement, market research to payment and registration forms. With built-in research expertise and AI-powered technology, it’s like having a team of expert researchers at your fingertips. Trusted by millions—from startups to Fortune 500 companies—SurveyMonkey helps teams gather insights and information that inspire better decisions, create experiences people love, and drive business growth. Discover how at surveymonkey.com . What we’re looking for We are seeking a visionary Director of Engineering to lead the Platform Services team. This critical leadership role drives the architecture, development, and operation of the foundational services powering our next-generation SaaS product. The ideal candidate will possess a strong background in scaling SaaS platforms, deep expertise in security services (Identity, AuthZ/AuthN), and proven experience building enterprise-grade administration and internal tooling. This role will define technical strategy, foster engineering excellence, and manage a high-performing team to deliver robust, scalable, and secure platform capabilities. What you’ll be working on Strategy and Leadership Define and execute the Platform Services technical roadmap, ensuring alignment with company strategy and security requirements. Lead, mentor, and grow a high-performing engineering team, fostering a culture of innovation and rigor. Establish and enforce best practices for software development, QA, deployment, and operational excellence (DevOps/SRE). Manage budgets, resource allocation, and project timelines for the Platform Services domain. Platform Development and Architecture Identity and Access Management (IAM): Own the strategy and delivery for core security services (Identity, AuthN, AuthZ), including SSO, OAuth 2.0/OIDC, and Role-Based Access Control (RBAC). Enterprise Administration: Architect and implement scalable, multi-tenant solutions for enterprise customer administration, user provisioning, and account management at scale. Internal Tooling: Oversee the development of secure, efficient, and user-friendly Customer Service Administration Tools for platform support, auditing, and debugging. Drive the adoption of modern microservices architecture, cloud-native patterns, and performance optimization for high availability and low latency. Collaboration and Security Partner with Product Management to translate business requirements into technical specifications and clear development plans. Collaborate with Security and Compliance teams to ensure all services meet stringent security standards (e.g., SOC 2, ISO 27001) and maintain robust logging and auditing capabilities. Work with other Engineering Directors to seamlessly integrate Platform Services into product-facing features and infrastructure. We’d love to hear from people with 10+ years of software engineering experience, with 4+ years in a senior leadership role managing multiple engineering teams in a high-growth SaaS environment. Bachelor's or Master's degree in Computer Science or a related field (or equivalent practical experience), combined with excellent communication, negotiation, and stakeholder management skills. Proven track record in building and scaling mission-critical, 24/7 services. Extensive knowledge of core platform services, including AuthN/AuthZ protocols, modern IAM systems, federation, cryptographic security best practices, and architecting multi-tenant/enterprise administration solutions. Strong architectural understanding of distributed systems, microservices, and cloud computing platforms (AWS, Azure, or GCP). Experience with specific identity providers (e.g., Okta, Auth0, Ping Identity). Hands-on experience with modern DevOps practices: CI/CD, Infrastructure-as-Code (Terraform), and cloud monitoring/logging tools. Prior experience building robust, internal-facing tools for operations or customer support. SurveyMonkey believes in-person collaboration is valuable for building relationships, fostering community, and enhancing our speed and execution in problem-solving and decision-making. As such, you will be required to work from a SurveyMonkey office up to 1 day per week. #LI-Hybrid Why SurveyMonkey? We’re glad you asked At SurveyMonkey, curiosity powers everything we do. We’re a global company where people from all backgrounds can make an impact, build meaningful connections, and grow their careers. Our teams work in a flexible, hybrid environment with thoughtfully designed offices and programs like the CHOICE Fund to help employees thrive in work and life. We’ve been trusted by organizations for over 25 years, and we’re just getting started. Our milestones include celebrating a quarter-century of curiosity with 25 acts of giving , opening new hubs in Costa Rica and Indi",https://aijobs.ai/job/director-of-engineering-platform-services
Software Engineer II,Momentive,"Ottawa,  Canada",Hybrid,Mid-level,3000.0,5000.0,4000.0,"JavaScript, AWS, Python, Node.js, CI/CD","SurveyMonkey is the world’s most popular platform for surveys and forms, built for business—loved by users. We combine powerful capabilities with intuitive design, effectively serving every use case, from customer experience to employee engagement, market research to payment and registration forms. With built-in research expertise and AI-powered technology, it’s like having a team of expert researchers at your fingertips. Trusted by millions—from startups to Fortune 500 companies—SurveyMonkey helps teams gather insights and information that inspire better decisions, create experiences people love, and drive business growth. Discover how at surveymonkey.com . What we’re looking for The Growth Platform team develops critical tools and infrastructure that empower our company to make data-driven decisions. As part of this team, you’ll enhance SDKs, backend services, admin panels and integrate with third-party analytics providers. Your work will directly impact key business outcomes and support our stakeholders across the organization. You will have the opportunity to utilize AI to automate workflows and enhance our tools. What you’ll be working on Develop and maintain backend services, SDKs, and admin panels. Integrate with third-party services to support experimentation, metrics, and analytics. Collaborate closely with our community and provide guidance on the usage of our tools and infrastructure. Use AI to automate tasks and enhance our platform. We’d love to hear from people with 3-5 years of full-stack development experience focusing on building scalable, reliable backend systems. Strong experience with code reviews, writing technical specifications, and a culture of producing high-quality code. Expertise in software engineering best practices, including automated testing, version control, and CI/CD pipelines. Proficiency with Python and/or JavaScript (Node.js). Experience with cloud computing platforms like AWS. Nice to have: Experience with Experimentation, A/B Testing, and/or Product Analytics tools Nice to have: Experience with using AI to automate workflows (AWS Bedrock, LangChain, etc.) SurveyMonkey believes in-person collaboration is valuable for building relationships, fostering community, and enhancing our speed and execution in problem-solving and decision-making. As such, you will be required to work from a SurveyMonkey office up to 1 day per week. #LI-Hybrid Why SurveyMonkey? We’re glad you asked At SurveyMonkey, curiosity powers everything we do. We’re a global company where people from all backgrounds can make an impact, build meaningful connections, and grow their careers. Our teams work in a flexible, hybrid environment with thoughtfully designed offices and programs like the CHOICE Fund to help employees thrive in work and life. We’ve been trusted by organizations for over 25 years, and we’re just getting started. Our milestones include celebrating a quarter-century of curiosity with 25 acts of giving , opening new hubs in Costa Rica and India , crossing the threshold of 100 billion questions answered , and earning recognition as one of the Most Inspiring Workplaces across North America and Asia . We live our company values —like championing inclusion and making it happen—by embedding them into how we hire, collaborate, and grow. They help shape everything from our culture to our business decisions. Come join us and see where your curiosity can take you. Our commitment to an inclusive workplace SurveyMonkey is an equal opportunity employer committed to providing a workplace free from harassment and discrimination. We celebrate the unique differences of our employees because that is what drives curiosity, innovation, and the success of our business. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, gender identity or expression, age, marital status, veteran status, disability status, pregnancy, parental status, genetic information, political affiliation, or any other status protected by the laws or regulations in the locations where we operate. Accommodations are available for applicants with disabilities.",https://aijobs.ai/job/software-engineer-ii-36
"Principal Engineer, AI Compiler",Tenstorrent,"Toronto,  Ontario,  Canada",Hybrid,Senior,100000.0,500000.0,300000.0,"Python, TensorFlow, PyTorch","Tenstorrent is leading the industry on cutting-edge AI technology, revolutionizing performance expectations, ease of use, and cost efficiency. With AI redefining the computing paradigm, solutions must evolve to unify innovations in software models, compilers, platforms, networking, and semiconductors. Our diverse team of technologists have developed a high performance RISC-V CPU from scratch, and share a passion for AI and a deep desire to build the best AI platform possible. We value collaboration, curiosity, and a commitment to solving hard problems. We are growing our team and looking for contributors of all seniorities. Join the team revolutionizing AI computing at Tenstorrent. In this role you will lead development on TT-Forge, our MLIR-based compiler, and manage a team focused on scaling graph transformations, lowering passes, and kernel-level optimizations. You’ll help shape the future of AI computing through compiler technology that is fast, flexible, and built for real-world models. This role is hybrid, based out of Toronto, ON. We welcome candidates at various experience levels for this role. During the interview process, candidates will be assessed for the appropriate level, and offers will align with that level, which may differ from the one in this posting. Who You Are Extensive experience building compilers or similar systems, with strong fluency in C++ and Python. Strong knoweledge of MLIR, LLVM, or related infrastructure, with hands-on work in dialect design or optimization passes. You have a strong understanding of modern AI frameworks like PyTorch, TensorFlow, or JAX, including how models are transformed and executed. A background in working across teams to ship reliable, scalable tools in fast-paced engineering environments. What We Need Leadership to drive compiler development across multiple layers of the stack, including custom dialects, transformation passes, and runtime integration. Alignment with hardware, software, and ML teams to ensure the compiler supports realistic performance and deployment needs. Technical ownership of roadmap priorities, planning, and mentorship for a high-performing engineering team. Insight to identify bottlenecks, debug performance issues, and improve developer workflows across the stack. What You Will Learn How to build compiler infrastructure that supports both training and inference at scale across custom chip architectures. New approaches for human-in-the-loop optimization using TT-Explorer and other internal tooling. Best practices for evolving MLIR dialects like TTIR, TTNN, and TTKernel to support next-generation AI workloads. How Tenstorrent delivers open, performant, and developer-friendly AI infrastructure that scales with industry demands. Compensation for all engineers at Tenstorrent ranges from $100k - $500k including base and variable compensation targets. Experience, skills, education, background and location all impact the actual offer made. Tenstorrent offers a highly competitive compensation package and benefits, and we are an equal opportunity employer. This offer of employment is contingent upon the applicant being eligible to access U.S. export-controlled technology.  Due to U.S. export laws, including those codified in the U.S. Export Administration Regulations (EAR), the Company is required to ensure compliance with these laws when transferring technology to nationals of certain countries (such as EAR Country Groups D:1, E1, and E2).   These requirements apply to persons located in the U.S. and all countries outside the U.S.  As the position offered will have direct and/or indirect access to information, systems, or technologies subject to these laws, the offer may be contingent upon your citizenship/permanent residency status or ability to obtain prior license approval from the U.S. Commerce Department or applicable federal agency.  If employment is not possible due to U.S. export laws, any offer of employment will be rescinded.",https://aijobs.ai/job/principal-engineer-ai-compiler
Director of AI Engineering,Apollo.io,"Remote,  Canada; Remote,  United States",Non spécifié,Senior,0.0,450000.0,225000.0,"AWS, Python, Go, GCP, Machine Learning","Apollo.io is the leading go-to-market solution for revenue teams, trusted by over 500,000 companies and millions of users globally, from rapidly growing startups to some of the world's largest enterprises. Founded in 2015, the company is one of the fastest growing companies in SaaS, raising approximately $250 million to date and valued at $1.6 billion. Apollo.io provides sales and marketing teams with easy access to verified contact data for over 210 million B2B contacts and 35 million companies worldwide, along with tools to engage and convert these contacts in one unified platform. By helping revenue professionals find the most accurate contact information and automating the outreach process, Apollo.io turns prospects into customers. Apollo raised a series D in 2023 and is backed by top-tier investors, including Sequoia Capital, Bain Capital Ventures, and more, and counts the former President and COO of Hubspot, JD Sherman, among its board members. Apollo.io is the AI-native GTM platform used by millions of professionals worldwide, helping revenue teams automate workflows, personalize outreach, and convert prospects into customers. Backed by Sequoia and Bain Capital and valued at $1.6B+, Apollo is one of the fastest-growing SaaS companies in the world, shipping AI-first capabilities across assistants, agentic automation, search, and generation at massive scale. We are entering a hyper-growth phase of AI innovation and are hiring a Director of AI Engineering to lead the strategy, engineering execution, and cross-functional integration of Apollo’s applied AI systems. Your Role & Mission As the Director of AI Engineering, you will own the end-to-end delivery of Apollo’s AI roadmap spanning autonomous agentic systems, LLM-powered workflows, search & relevance, personalization, and production-grade ML infrastructure. You will lead and scale a high-impact AI Engineering organization responsible for turning cutting-edge AI techniques into real, revenue-driving product capabilities used by millions. This role sits at the intersection of Engineering, Product, Machine Learning, Growth, and GTM , requiring deep technical leadership, exceptional product intuition, and a track record of shipping AI systems that create measurable business outcomes. You will define the long-term architecture for agentic AI at Apollo, elevate engineering excellence, mentor senior ICs and managers, and accelerate Apollo’s position as the AI-native leader in the go-to-market ecosystem. What You’ll Own & Deliver AI Systems Strategy & Roadmap Define the multi-year technical vision for Apollo’s AI stack, spanning agents, orchestration, inference, retrieval, and platformization. Prioritize high-impact AI investments by partnering with Product, Design, Research, and Data leaders to align engineering outcomes with business goals. Establish technical standards, evaluation criteria, and success metrics for every AI-powered feature shipped. Agentic Systems & Applied AI Delivery Lead the architecture and deployment of long-horizon autonomous agents , multi-agent workflows, and API-driven orchestration frameworks. Build reusable, scalable agentic components that power GTM workflows like research, enrichment, sequencing, lead scoring, routing, and personalization. Own the evolution of Apollo’s internal LLM platform for high-scale, low-latency, cost-optimized inference. AI Assistants, Search & Personalization Oversee model-driven experiences for natural-language interfaces, RAG pipelines, semantic search, personalized recommendations, and email intelligence. Partner with Product & Design to build intuitive conversational UX that hides underlying complexity while elevating user productivity. Experimentation, Evaluation & Observability Implement rigorous evaluation frameworks, including offline benchmarking, human-in-the-loop review, and online A/B experimentation. Ensure robust observability, monitoring, and safety guardrails for all AI systems in production. Drive continuous model improvement through telemetry, feedback loops, and data-driven performance tuning. Technical Leadership & Team Building Build and lead a world-class AI Engineering team of senior ICs, managers, and cross-functional collaborators. Foster a culture of experimentation, velocity, and pragmatic engineering, where speed and safety coexist. Mentor engineers on system design, LLM architectures, distributed systems, and applied ML best practices. Upskill the broader engineering org in AI-native development, tooling, and automation. Cross-Functional Impact & Execution Excellence Collaborate closely with Data Science, Product, Design, and Research teams to ensure AI capabilities integrate seamlessly into the GTM user journey. Accelerate learning cycles by combining LLM experimentation, product iteration, telemetry insights, and engineering automation. What We’re Looking For Technical & Production Expertise 10–15+ years in software engineering, with significant leadership experience owni",https://aijobs.ai/job/director-of-ai-engineering
"Software Engineer, Autonomous Vehicles",Helm.ai,"Remote,  United States",On-site,Senior,,,,Python,"We help make autonomous technologies more efficient, safer, and accessible. Helm.ai builds AI software for autonomous driving and robotics. Our Deep Teaching™ methodology is uniquely data and capital efficient, allowing us to surpass traditional approaches. Our unsupervised learning software can train neural networks without the need for human annotation or simulation and is hardware-agnostic. We work with some of the world's largest automotive manufacturers and we've raised over $100M from Honda, Goodyear Ventures, Mando, and others to help us scale. Our team is made up of people with a diverse set of experiences in software and academia. We work together towards one common goal: to integrate the software you'll help us build into hundreds of millions of vehicles. We are looking for versatile engineers to shape core components of the next generation of the Helm.ai autonomous stack. No prior experience in autonomous vehicles is required—we prioritize deep expertise in backend systems and a proven track record in high-impact software engineering. In this senior role, you will design, implement, and test safe, efficient, and reliable vehicle software/hardware systems, collaborate with sensor and compute vendors, partner with Helm.ai’s AI teams, and work with customers to advance highway and urban autonomous driving capabilities. You will: Design, develop, and deliver safe, scalable, and robust real-time software for mass production grade autonomous vehicle systems directly contributing to safer roads and economically viable AI deployment. Conduct in-depth algorithm analysis, optimization, and iteration to enhance efficiency and accuracy across the AV stack. Architect scalable continuous learning system for deploying new ML models, monitoring their performance, and prioritizing improvements. Collaborate with platform, embedded, and AI teams to ensure cohesive development, validation, and integration of ML based perception, prediction, and planning. Stay abreast of industry trends and emerging tools in high-performance computing, real-time systems, and AI-driven mobility. You have: Bachelor’s or Master’s degree in Computer Science, Electrical Engineering, Robotics; Ph.D. preferred. Demonstrated ability to lead projects, mentor team members, and work autonomously in high-stakes fast-paced environments. Strong foundation in backend programming (C++, Python) and proven track record in designing, developing, and deploying performant and/or real-time software systems, e.g. aerospace, online ads, robotics, gaming, high-frequency trading. Strong command of data structures, algorithms, software architecture, and design patterns. Excellent problem-solving, communication, and collaboration skills, with a passion for innovation. The following are not required but a plus : Experience in autonomous vehicle development, with expertise in software/hardware integration. Experience with ROS2 or other robotics middleware. Experience with ML model deployment and monitoring in production environments, including data pipeline management and model versioning for safety-critical systems. Expertise in simulation tools (e.g., CARLA) and real-world testing protocols for autonomous vehicles. We offer: Competitive health insurance options 401K plan management Free lunch and fully-stocked kitchen in our South Bay office Additional perks: monthly wellness stipend, office set up allowance, company retreats, and more to come as we scale The opportunity to work on one of the most interesting, impactful problems of the decade Helm.ai is proud to be an equal opportunity employer building a diverse and inclusive workforce. All applicants will be considered for employment without attention to race, color, religion, sex, sexual orientation, gender identity, national origin, veteran or disability status. Any unsolicited resumes/candidate profiles submitted through our website or to personal email accounts of employees of Helm.ai are considered the property of Helm.ai and are not subject to payment of agency fees.",https://aijobs.ai/job/software-engineer-autonomous-vehicles
"Sr. Engineer, SoC Design Verification – AI/ML Accelerator Chiplets",Tenstorrent,"Toronto,  Ontario,  Canada",Hybrid,Senior,,,,Python,"Tenstorrent is leading the industry on cutting-edge AI technology, revolutionizing performance expectations, ease of use, and cost efficiency. With AI redefining the computing paradigm, solutions must evolve to unify innovations in software models, compilers, platforms, networking, and semiconductors. Our diverse team of technologists have developed a high performance RISC-V CPU from scratch, and share a passion for AI and a deep desire to build the best AI platform possible. We value collaboration, curiosity, and a commitment to solving hard problems. We are growing our team and looking for contributors of all seniorities. Tenstorrent is seeking a SoC Design Verification Engineer on the AI/ML chiplet verification team, who will play a key role in ensuring the functionality, performance, and reliability of advanced AI/ML accelerator chiplets. Working closely with a diverse array of technical teams —including software, architecture, and IP design—you will design complex verification environments, develop structured test plans, and tackle exciting challenges to validate cutting-edge hardware. This role is hybrid, based out of Toronto, ON or Ottawa, ON. We welcome candidates at various experience levels for this role. During the interview process, candidates will be assessed for the appropriate level, and offers will align with that level, which may differ from the one in this posting. Who You Are Proficient in SystemVerilog/UVM, Python, and C/C++, with strong design verification skills. Experienced in collaborating with cross-functional teams (architecture, software, and IP teams) to develop test plans, infrastructure, and debug tightly coupled hardware/software. Familiar with and excited by AI-assisted tools like Cursor or Claude Code to enhance productivity. Hands-on experience with AI accelerator hardware, Network-on-Chip design, and/or embedded FW design is a plus. What We Need Collaborate with architecture, IP, and software teams to develop and execute comprehensive test plans for AI/ML accelerator chiplets. Design and implement hybrid verification environments , coordinating several embedded firmware threads with traditional testbench components like monitors, transactors, and checkers. Partner with software and architecture teams to drive performance verification and ensure chiplets meet competitive performance targets. What You Will Learn Deep knowledge of AI hardware architectures, including scalable accelerator designs, network-on-chip performance optimization, and multi-die scaling strategies. Insight into silicon-to-software co-design principles , enabling AI accelerators that push the boundaries of performance and capabilities. Tenstorrent offers a highly competitive compensation package and benefits, and we are an equal opportunity employer. This offer of employment is contingent upon the applicant being eligible to access U.S. export-controlled technology.  Due to U.S. export laws, including those codified in the U.S. Export Administration Regulations (EAR), the Company is required to ensure compliance with these laws when transferring technology to nationals of certain countries (such as EAR Country Groups D:1, E1, and E2).   These requirements apply to persons located in the U.S. and all countries outside the U.S.  As the position offered will have direct and/or indirect access to information, systems, or technologies subject to these laws, the offer may be contingent upon your citizenship/permanent residency status or ability to obtain prior license approval from the U.S. Commerce Department or applicable federal agency.  If employment is not possible due to U.S. export laws, any offer of employment will be rescinded.",https://aijobs.ai/job/sr-engineer-soc-design-verification-aiml-accelerator-chiplets
Principal Embedded SW/FW Engineer (Bringup),Graphcore,"Austin,  Texas,  United States",Hybrid,Lead/Principal,100000.0,326000.0,213000.0,Python,"Principal Embedded SW/FW Engineer (Bringup) Salary $241,100 - $326,100 + Phantom Equity + Benefits Graphcore is a globally recognised leader in Artificial Intelligence computing systems. The company designs advanced semiconductors and data centre hardware that provide the specialised processing power needed to drive AI innovation, while delivering the efficiency required to support its broader adoption. As part of the SoftBank Group, Graphcore is a member of an elite family of companies responsible for some of the world’s most transformative technologies. We are opening a new AI Engineering Campus in Austin which will play a central role in Graphcore's work building the future of AI computing. We are looking to hire Post-Silicon Validation Engineers to join our collaborative, cross-functional development team validating cutting edge, high performance AI chips and platforms. You will play a critical role in supporting new product introductions and post-silicon validation. Working within the Post-Silicon Validation team, you will be involved with bringing first silicon to life, functionally validating it and working closely with many other teams to help it become a fully characterised and working product, reporting project status/progress to program management on a regular basis. You will have the opportunity to, and be responsible for, leading, mentoring, and providing technical guidance to other engineering team members. In this role, you can leverage your experience and industry knowledge to architect and drive implementation of continuous improvements to test infrastructure and processes. The Post-Silicon Validation team sits within the Architecture and Validation team, we are responsible for validation of new silicon when it returns from manufacture, enabling and supporting the production SW and FW teams to bring up their software and also supporting the Silicon Characterisation team. Responsibilities and Duties Plan, design, develop and debug silicon validation tests in bare metal C/C++ on FPGA/Emulator prior to first silicon Deploy silicon validation tests on first silicon and debugging them Develop automated test framework and regression test suites in Python to optimize validation efficiency Collaborate closely with engineers from many other disciplines on a variety of topics Work with Validation and Production Test engineering peers to implement best practices and continuous improvements to test methodologies Analyse test results, identify and debug failures/defects Contribute to shared test and validation infrastructure Provide feedback to architects Essential skills: Strong experience in Bare metal / embedded C/C++ Good knowledge of digital ASICs Be highly motivated, a self starter, and a team player Ability to work across teams and programming languages to find root causes of deep and complex issues Experience of the post-silicon validation process applied in digital ASIC environments Python, Linux Excellent communication skills and the ability to collaborate with others to solve problems Excellent problem-solving, analytical & diagnostic skills Desirable skills: Driver level experience with one or more of the following is highly desirable: PCIe Ethernet Memory technologies (LPDDR, DDR, HBM, …) Other peripherals such as I2C, I3C, SPI, … Good knowledge of mixed-signal building blocks such as PLLs, high speed PHYs and IC control/communication protocols is highly desirable Experience of Arm CPUs , System IP and debug tools Experience of AMBA protocols Understanding of ML applications and their workloads Experience in Characterization, Failure Analysis, Test Development, Statistical analysis, and Customer Support Benefits: In addition to a competitive salary, Graphcore offers a competitive benefits package. We welcome people of different backgrounds and experiences; we’re committed to building an inclusive work environment that makes Graphcore a great home for everyone. We offer an equal opportunity process and understand that there are visible and invisible differences in all of us. We can provide a flexible approach to interview and encourage you to chat to us if you require any reasonable adjustments.",https://aijobs.ai/job/principal-embedded-swfw-engineer-bringup
Machine Learning Engineer,PitchBook Data,"New York,  United States",Remote,Junior,0.0,180000.0,90000.0,"Scikit-learn, Python, Java, Docker, Kubernetes, Kafka, Machine Learning, TensorFlow, PyTorch","At PitchBook, a Morningstar company, we are always looking forward. We continue to innovate, evolve, and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy, and fun that reverberates throughout the company. Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast, and do it all over again in the pursuit of excellence. If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you. About the Role: As a member of the Product and Engineering team at PitchBook, you will be part of a team of big thinkers, innovators, and problem solvers who strive to deepen the positive impact we have on our customers and our company every day. We value curiosity and the drive to find better ways of doing things. We thrive on customer empathy, which remains our focus when creating excellent customer experiences through product innovation. We know that greatness is achieved through collaboration and diverse points of view, so we work closely with partners around the globe. As a team, we assume positive intent in each other’s words and actions, value constructive discussions, and foster a respectful working environment built on integrity, growth, and business value. We invest heavily in our people, who are eager to learn and constantly improve. Join our team and grow with us! As a Machine Learning Engineer (MLE) on the AI & ML (Insights) team, you will play a critical role in delivering AI-powered features that extract meaningful insights from PitchBook’s wealth of structured and unstructured data including reports, news, and other textual content. This role requires deep technical expertise in advanced data analytics and machine learning, as well as a hands-on approach to designing, building, and optimizing ML solutions that power user-facing features on the PitchBook Platform. You will be deeply involved in the end-to-end development and operationalization of ML models, including their architecture, training, deployment, and ongoing maintenance. Your focus will span across natural language processing (NLP), generative AI (GenAI), large language models (LLMs), and scalable data systems. You will be expected to tackle complex technical challenges, contribute to architectural decisions, and collaborate closely with other engineers, data scientists, and product managers to ensure that your work aligns with business goals and AI/ML strategy. Your contributions will help unlock unique value for PitchBook customers by improving the speed, discoverability, quality, and quantity of insights available on the platform. This includes developing models that can infer meaning and structure from millions of discrete data sources and applying ML to enrich our datasets with predictive and generative intelligence. Primary Job Responsibilities: Deliver high-impact AI and ML capabilities that drive insight generation on the PitchBook Platform. Ensure your work contributes to broader business goals and is aligned with the team's strategic priorities Provide hands-on expertise in designing, building, and deploying AI/ML models and services with a focus on NLP, summarization, semantic search, classification, and prediction. Contribute to the development of scalable, high-performance systems that meet production-grade reliability and efficiency standards Contribute to a culture of technical excellence by sharing knowledge, pairing with teammates, and actively participating in code and design reviews. Provide situational guidance to junior engineers and contribute to team best practices Build and optimize models that leverage classifiers, transformers, LLMs, and other NLP techniques to generate meaningful insights from structured and unstructured data. Integrate these models into the broader AI/ML infrastructure in collaboration with partner teams Collaborate with engineering, product management, and data collection teams to ensure models are informed by high-quality data and support strategic product goals Explore and experiment with emerging technologies, methodologies, and tools in the fields of GenAI, NLP, and search. Translate research findings into practical solutions that enhance PitchBook’s AI capabilities Contribute to best practices in model transparency, monitoring, evaluation, and compliance. Help maintain high standards of security, data integrity, and responsible AI use across your projects Participate in the technical evaluation of candidates and help onboard new team members by contributing to documentation, pairing, and knowledge-sharing practices Apply principles from Agile, Lean, and Fast-Flow",https://aijobs.ai/job/machine-learning-engineer-2480
Senior Software Engineer - AI Applications,Guidepoint,"Toronto,  Ontario,  Canada",Hybrid,Senior,,,,"Azure, JavaScript, Python, Node.js, Elasticsearch, TypeScript, MongoDB, CI/CD, RabbitMQ, Go, Docker, Kubernetes, Kafka, PostgreSQL","Overview: Guidepoint seeks an experienced Senior Software Engineer as an integral member of the Toronto-based Data/AI team. The Toronto Technology Hub serves as the base of our Data/AI/ML team, dedicated to building a modern data infrastructure for advanced analytics and the development of responsible AI. This strategic investment is integral to Guidepoint’s vision for the future, aiming to develop cutting-edge Generative AI and analytical capabilities that will underpin Guidepoint’s Next-Gen research enablement platform and data products. You will develop and scale Generative AI-powered systems, including large language model (LLM) applications. Guidepoint’s Technology team thrives on problem-solving and creating happier users. As Guidepoint works to achieve its mission of making individuals, businesses, and the world smarter through personalized knowledge-sharing solutions, the engineering team is taking on challenges to improve our internal application architecture and create new AI-enabled products to optimize the seamless delivery of our services. This is a hybrid position based in Toronto. What You will Do: You'll be instrumental in taking product ideas from initial concept to full-scale platform, handling everything from rapid prototyping to building robust, scalable systems Design and develop core backend services and APIs that support our AI applications and data products Expertise on core engineering skills - Cloud, microservice architecture, caching, queuing Own systems end-to-end including (but not limited to) design, code, monitoring, observability for Engineering Projects and training, testing, deployment and iteration for model training projects Hands-on coding and development using Node.js/Typescript and Python technologies for backend development Solid experience with Elasticsearch/OpenSearch & Elastic Stack, including index design, query optimization, and cluster management Strong understanding of Software development (design patterns, REST, system design) Experience with relational databases and NoSQL databases Collaborate with cross-functional teams, including product managers, to understand project requirements Implement and advocate for continuous integration and continuous delivery (CI/CD) practices Ensure adherence to best practices and coding standards in software design and development What You Have: Bachelor's Degree or equivalent Proficiency in modern programming languages (e.g., Python, JavaScript/TypeScript, Go, etc.) Experience with continuous integration and continuous deployment (CI/CD) pipelines and managing application deployments in a containerized environment. (Docker, Kubernetes) Proven experience designing and deploying applications using Generative AI and large language models (e.g., GPT-4, Claude, Gemini, open-weight LLMs) Experience with retrieval-augmented generation, embeddings-based search, agent orchestration, or prompt chaining Demonstrated leadership ability in building and scaling AI/ML systems Excellent communication and collaboration skills across engineering, product, and business stakeholders Nice-to-Have: Experience designing Generative AI (GenAI) systems for end-user applications like research assistants, content summarizers, or copilots Understanding of the challenges and best practices for building compliant and explainable AI solutions, especially in regulated industries Hands-on experience with Kubernetes (preferably Azure Kubernetes Service) Experience with NoSQL databases (e.g., Elasticsearch, MongoDB) and SQL databases (e.g., PostgreSQL, MS SQL) Experience building data and system integrations using various technologies, including message queues (e.g., RabbitMQ) and Kafka You will also be eligible for the following benefits: Paid Time Off Comprehensive benefits plan Company RRSP Match Development opportunities through the LinkedIn Learning platform About Guidepoint: Guidepoint is a leading research enablement platform designed to advance understanding and empower our clients’ decision-making process. Powered by innovative technology, real-time data, and hard-to-source expertise, we help our clients to turn answers into action. Backed by a network of nearly 1.75 million experts, and Guidepoint’s 1,600 employees worldwide, we inform leading organizations’ research by delivering on-demand intelligence and research on request. With Guidepoint, companies and investors can better navigate the abundance of information available today, making it both more useful and more powerful. At Guidepoint, our success relies on the diversity of our employees, advisors, and client base, which allows us to create connections that offer a wealth of perspectives. We are committed to upholding policies that contribute to an equitable and welcoming environment for our community, regardless of background, identity, or experience. #LI- SP1 #LI-Hybrid",https://aijobs.ai/job/senior-software-engineer-ai-applications-5
Machine Learning Engineer ll,Cohere Health,United States,Remote,Lead/Principal,2000.0,4000.0,3000.0,"Python, Machine Learning, PyTorch","Opportunity Overview: We are looking for a Machine Learning Engineer ll to join our team! Our ML team’s work is focused on designing, deploying, and monitoring production models which extract or predict relevant clinical findings from structured and unstructured data sources. In this role, you’ll join our growing team of world-class engineers, statisticians, and clinical experts to deploy machine learning algorithms that help automate burdensome administrative clinical practices. You will be tasked with finding the most promising opportunities for impact and then delivering on them. This is a unique opportunity to join a high caliber engineering team that is growing quickly. You will build impactful healthcare technology on a modern tech stack. What you’ll do: Perform in-depth analysis of healthcare data to independently design, develop, and deliver clinical ML models. Build reliable and scalable production machine learning systems Work on feature engineering, statistical analysis, developing novel ML techniques, understanding performance, and improving model run time. Work cross-functionally across diverse stakeholders, including product managers, statisticians, clinicians, and clinical analysts. What you’ll need: You have 2-4 years full time professional experience in Machine Learning You have an MS in computer science, machine learning, computational linguistics, statistics, mathematics or similar field You have hands on experience building with modern language models, including context-engineering LLMs or fine-tuning SLMs You understand scientific best practice in experimental design and can independently perform data collection, measurement, and interpretation of results You have experience configuring, training, evaluating, deploying, and maintaining models in a production setting Advanced proficiency in Python and familiarity with ML frameworks such as PyTorch. Pay & Perks: 💻 Fully remote opportunity with about 5% travel 🩺 Medical, dental, vision, life, disability insurance, and Employee Assistance Program 📈 401K retirement plan with company match; flexible spending and health savings account 🏝️ Up to 184 hours (23 days) of PTO per year + company holidays 👶 Up to 14 weeks of paid parental leave 🐶 Pet insurance The salary range for this position is $100,000 - $135,000 annually; as part of a total benefits package which includes health insurance, 401k and bonus. In accordance with state applicable laws, Cohere is required to provide a reasonable estimate of the compensation range for this role. Individual pay decisions are ultimately based on a number of factors, including but not limited to qualifications for the role, experience level, skillset, and internal alignment. Interview Process*: Connect with Talent Acquisition for a Preliminary Phone Screening Meet your Hiring Manager! Behavioral Interview(s) Live Coding Case Study *Subject to change About Cohere Health: Cohere Health’s clinical intelligence platform delivers AI-powered solutions that streamline access to quality care by improving payer-provider collaboration, cost containment, and healthcare economics. Cohere Health works with over 660,000 providers and handles over 12 million prior authorization requests annually. Its responsible AI auto-approves up to 90% of requests for millions of health plan members. With the acquisition of ZignaAI, we’ve further enhanced our platform by launching our Payment Integrity Suite, anchored by Cohere Validate™, an AI-driven clinical and coding validation solution that operates in near real-time. By unifying pre-service authorization data with post-service claims validation, we’re creating a transparent healthcare ecosystem that reduces waste, improves payer-provider collaboration and patient outcomes, and ensures providers are paid promptly and accurately. Cohere Health’s innovations continue to receive industry wide recognition. We’ve been named to the 2025 Inc. 5000 list and in the Gartner® Hype Cycle™ for U.S. Healthcare Payers (2022-2025), and ranked as a Top 5 LinkedIn™ Startup for 2023 & 2024. Backed by leading investors such as Deerfield Management, Define Ventures, Flare Capital Partners, Longitude Capital, and Polaris Partners, Cohere Health drives more transparent, streamlined healthcare processes, helping patients receive faster, more appropriate care and higher-quality outcomes. The Coherenauts, as we call ourselves, who succeed here are empathetic teammates who are candid, kind, caring, and embody our core values and principles . We believe that diverse, inclusive teams make the most impactful work. Cohere is deeply invested in ensuring that we have a supportive, growth-oriented environment that works for everyone. We can’t wait to learn more about you and meet you at Cohere Health! Equal Opportunity Statement: Cohere Health is an Equal Opportunity Employer. We are committed to fostering an environment of mutual respect where equal employment opportunities are available to all.  To us, it’s per",https://aijobs.ai/job/machine-learning-engineer-ll
"Senior Lead Machine Learning Engineer, Agentic AI",Upwork,"Toronto,  Ontario,  Canada",On-site,Senior,,,,"JavaScript, Microservices, Python, CI/CD, Java, Go, Machine Learning","Upwork Inc.’s (Nasdaq: UPWK) family of companies connects businesses with global, AI-enabled talent across every contingent work type including freelance, fractional, and payrolled. This portfolio includes the Upwork Marketplace, which connects businesses with on-demand access to highly skilled talent across the globe, and Lifted, which provides a purpose-built solution for enterprise organizations to source, contract, manage, and pay talent across the full spectrum of contingent work. From Fortune 100 enterprises to entrepreneurs, businesses rely on Upwork Inc. to find and hire expert talent, leverage AI-powered work solutions, and drive business transformation. With access to professionals spanning more than 10,000 skills across AI & machine learning, software development, sales & marketing, customer support, finance & accounting, and more, the Upwork family of companies enables businesses of all sizes to scale, innovate, and transform their workforces for the age of AI and beyond. Since its founding, Upwork Inc. has facilitated more than $30 billion in total transactions and services as it fulfills its purpose to create opportunity in every era of work. Learn more about the Upwork Marketplace at Upwork.com Upwork ($UPWK) is the world’s human and AI-powered work marketplace that connects businesses with highly skilled, AI-enabled independent talent from across the globe. From entrepreneurs to Fortune 100 enterprises, companies rely on Upwork’s trusted platform and its mindful AI companion, Uma, to find and hire expert talent, leverage AI-powered work solutions, and drive business transformation. With on-demand access to professionals spanning more than 10,000 skills across AI & machine learning, software development, sales & marketing, customer support, finance & accounting, and more, Upwork enables businesses of all sizes to scale, innovate, and build agile teams for the age of AI and beyond. Upwork’s platform has facilitated more than $25 billion in economic opportunity for talent around the world. Learn more at Upwork.com and follow us on LinkedIn, Facebook, Instagram, TikTok, and X. We’re seeking a Senior Lead Machine Learning Engineer to architect, ship, and scale the next generation of agentic intelligence across Upwork. You will lead end‑to‑end development of AI agents and the platform that powers them—from LLM training and evaluation to runtime orchestration, safety, and developer APIs. This is a hands‑on, high‑impact role at the intersection of applied research and platform engineering, enabling internal teams and external developers to build reliable, safe, and high‑performing agents on Upwork. Responsibilities Build Agentic Intelligence. Design and implement multi‑agent systems (planning, tool‑use, memory, debate/critique, reflection) with robust guardrails and recovery strategies. Develop protocol‑aware agents and services that interoperate cleanly with developer tooling (e.g., agent frameworks and protocols such as MCP). Own reliability at scale: deterministic execution where needed, idempotency, timeouts/retries, and evaluation‑driven iteration on agent behavior. Train, Align, and Evaluate LLMs for Agents. Lead data strategy and curation for agent tasks; drive SFT, DPO, RLHF/RLAIF, and safety tuning tailored to multi‑tool, multi‑step workflows. Stand up evaluation harnesses for functional, task, and longitudinal metrics (success rate, time‑to‑completion, hallucination/escape rates, cost/latency). Build policy‑driven guardrails; partner with Legal/Security on data governance and privacy. Engineer Agentic Platform Backend Infrastructure. Architect low‑latency inference, retrieval, and orchestration services (streaming, event‑driven pipelines; scalable queues; caching; batching) with strong SLOs. Ship production‑grade services (APIs/SDKs, auth, rate limiting, observability) that make agent features easy to integrate for internal and external developers. Optimize cost/performance via quantization, distillation, model‑routing, and autoscaling; integrate evaluation signals directly into runtime and CI/CD. Lead, Partner, and Uplevel the Ecosystem. Provide technical leadership across research, product, and platform teams; mentor senior ICs; influence roadmaps with clear metrics and trade‑offs. Publish internal guidance and exemplar implementations; contribute to technical content, samples, and reference architectures for our agent platform. Define and track KPIs for data/quality/throughput, and drive continuous improvement using experiment results and production telemetry. What it takes to catch our eye Senior level experience applied ML/ML systems, with experience building LLM‑powered products; proven delivery of agentic workflows in production. Hands‑on mastery of LLM adaptation (prompting, tool/function calling), data curation, and safety/guardrails. Strong software fundamentals (distributed systems, transactions, consistency, resiliency) and experience building high‑throughput microservices/APIs",https://aijobs.ai/job/senior-lead-machine-learning-engineer-agentic-ai-1
Associate Machine Learning Engineer,PitchBook Data,"New York,  United States",Remote,Lead/Principal,0.0,150000.0,75000.0,"Python, Machine Learning","At PitchBook, a Morningstar company, we are always looking forward. We continue to innovate, evolve, and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy, and fun that reverberates throughout the company. Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast, and do it all over again in the pursuit of excellence. If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you. About the Role: As a member of the Product and Engineering team at PitchBook, you will be part of a team of big thinkers, innovators, and problem solvers who strive to deepen the positive impact we have on our customers and our company every day. We value curiosity and the drive to find better ways of doing things. We thrive on customer empathy, which remains our focus when creating excellent customer experiences through product innovation. We know that greatness is achieved through collaboration and diverse points of view, so we work closely with partners around the globe. As a team, we assume positive intent in each other’s words and actions, value constructive discussions, and foster a respectful working environment built on integrity, growth, and business value. We invest heavily in our people, who are eager to learn and constantly improve. Join our team and grow with us! PitchBook’s Associate Machine Learning Engineer is responsible for using machine learning, statistical modeling, and Natural Language Processing (NLP) to collect a high-volume of data for the PitchBook Platform and surface insights for the capital markets. This role requires curiosity and a strong desire to learn. A strong motivation to succeed is critical and everyone has the opportunity to shape the long-term direction of our team. Primary Job Responsibilities: Use natural language processing (NLP) and machine learning techniques to create novel views of private industry data Analyze and extract features from large amounts of unstructured data, determine most relevant features, and use clustering algorithms to drive insight into the data Analyze textual data such as articles and conversations to identify novel signals of private company performance Work closely with Product and Engineering teams to establish scalable, efficient, and automated processes for large scale data analyses and models Contribute to thought leadership on Data Science and Machine Learning best practices by staying informed of current trends in industry Support the vision and values of the company through role modeling and encouraging desired behaviors Participate in various company initiatives and projects as requested Skills and Qualifications: Bachelor’s degree in Computer Science, Machine Learning, Statistics, or related field Experience in a similar role in a production environment Experience or exposure with natural language processing (NLP) Experience or exposure with Python, R, or other relevant programming frameworks Experience or exposure in using SQL for data extraction Strong communication and data presentation skills Strong problem-solving ability Ability to communicate complex analysis in a clear, precise, and actionable manner Experience working closely a with software development team(s) a plus, but not required Financial services, investment, banking, venture capital and/or private equity knowledge, but not required Must be authorized to work in the United States without the need for visa sponsorship now or in the future Benefits + Compensation at PitchBook: Physical Health Comprehensive health benefits Additional medical wellness incentives STD, LTD, AD&D, and life insurance Emotional Health Paid sabbatical program after four years Paid family and paternity leave Annual educational stipend Ability to apply for tuition reimbursement CFA exam stipend Robust training programs on industry and soft skills Employee assistance program Generous allotment of vacation days, sick days, and volunteer days Social Health Matching gifts program Employee resource groups Subsidized emergency childcare Dependent Care FSA Company-wide events Employee referral bonus program Quarterly team building events Financial Health 401k match Shared ownership employee stock program Monthly transportation stipend *Please be aware the above PitchBook benefit and perk offerings are subject to corresponding plan and policy documents and may change during the course of your employment. Compensation Annual base salary: $110,000-$150,000 Target annual bonus percentage: 7.5% Working Conditions: At the heart of our company is a belief in the power of in-person colla",https://aijobs.ai/job/associate-machine-learning-engineer-1
Senior Engineering Manager - AI Platform (f/m/d),Contentful,"London,  England,  United Kingdom",Remote,Senior,,,,,"About the Opportunity Join Contentful’s AI Platform team as a Senior Engineering Manager - AI Platform (f/m/d) and play a pivotal role in shaping the next generation of AI-powered, developer-friendly platform capabilities. Our AI Platform teams are building the trusted foundation that enables Contentful and our customers to confidently deliver AI-enabled experiences. In this role, you will help drive two critical areas of our AI strategy: Empowering customers and internal teams to build accurate, trustworthy, and governed agentic solutions that are easy and intuitive to adopt. Providing enterprise-ready access to LLMs that enables product teams across Contentful to deliver secure, scalable, and reliable AI-powered features. This is an excellent opportunity for a technical manager who thrives at the intersection of product development, platform engineering, and cross-functional collaboration. Your work will amplify Contentful’s ability to bring innovative AI solutions to market, scaling impact across multiple teams and business functions. What to expect? Lead and scale high-performing engineering teams focused on core AI platform capabilities. Set and maintain a technical vision for scalable, developer-friendly tools that empower feature teams to rapidly and reliably build and integrate AI-powered solutions. Drive initiatives around modular AI actions, streaming support, observability, and traceability, ensuring compliance with AI content authenticity and regulatory requirements (such as EU AI Act and GDPR). Partner with Product, Design, and Engineering leaders to align strategic roadmaps and deliver measurable business value. Ensure AI capabilities (agentic frameworks and LLM platforms) are secure, governed, reliable, and intuitive. Serve as a consultant and enabler for product teams by delivering reusable, well-documented AI platform components and guiding adoption. Recruit, mentor, and coach team members to foster technical and leadership growth. Guide teams through the full lifecycle: discovery, design, implementation, scaling, and continuous improvement. Act as a thought partner to senior leadership, helping shape Contentful’s long-term AI strategy. Promote responsible AI development practices, including ethics, bias mitigation, and privacy. Monitor market and technology trends, evaluating emerging tools and methodologies. What you need to be successful 5+ years experience in technical leadership, specifically managing software/platform engineering teams; direct experience building platform products and infrastructure at scale. Proven track record delivering high-quality software and platform capabilities for internal and external customers. Deep engineering background including cloud architectures, containerization, and scalable APIs. Demonstrated ability to abstract complex AI technologies (LLMs, RAG, integrations) into usable, compliant, and extensible platform features. Strategic, data-driven thinking in translating business requirements into effective technical execution. Advanced stakeholder management and cross-functional collaboration skills. Experience embedding governance, compliance, and privacy (e.g., GDPR, CCPA, AI transparency requirements) within development practices. Outcome-oriented and pragmatic; focused on delivering tangible business impact and customer value. Entrepreneurial mindset; comfortable with ambiguity and change. Commitment to professional development and team growth. Excellent communication skills aligning diverse stakeholders. [Bonus] Experience in content management, digital experience platforms, or integrating AI/ML solutions into SaaS platforms. [Bonus] Understanding of AI ethics, bias mitigation, and responsible AI practices. What’s in it for you? Join an ambitious tech company reshaping the way people build digital experiences Full-time employees receive Stock Options for the opportunity to share in the success of our company Fertility and family building benefits, including a lifetime reimbursable wallet to support your growing family. We value Work-Life balance and You Time ! A generous amount of paid time off, including vacation days, sick days,  education days, compassion days for loss, and volunteer days Time off to care for and focus on your growing family Use your personal annual education budget to improve your skills and grow in your career Enjoy a full range of virtual and in-person events, including workshops, guest speakers, and fun team activities, supporting learning and networking exchange beyond the usual work duties An annual wellbeing stipend to care for your physical, financial, or emotional health A monthly communication phone/internet stipend and phone hardware upgrade reimbursement. New hire office equipment stipend for hybrid or distributed employees. Get the gear you need to work at your best. #LI-Remote #LI-KH1 Who are we? Contentful is a leading digital experience platform that helps modern businesses meet the growing demand for engaging, p",https://aijobs.ai/job/senior-engineering-manager-ai-platform-fmd-1
Applied Data Center Design Engineer,Cerebras Systems,"Toronto,  Ontario,  Canada",On-site,Lead/Principal,,,,"Python, Machine Learning","Cerebras Systems builds the world's largest AI chip, 56 times larger than GPUs. Our novel wafer-scale architecture provides the AI compute power of dozens of GPUs on a single chip, with the programming simplicity of a single device. This approach allows Cerebras to deliver industry-leading training and inference speeds and empowers machine learning users to effortlessly run large-scale ML applications, without the hassle of managing hundreds of GPUs or TPUs. Cerebras' current customers include global corporations across multiple industries, national labs, and top-tier healthcare systems. In January, we announced a multi-year, multi-million-dollar partnership with Mayo Clinic, underscoring our commitment to transforming AI applications across various fields. In August, we launched Cerebras Inference, the fastest Generative AI inference solution in the world, over 10 times faster than GPU-based hyperscale cloud inference services. About The Role As an Applied Data Center Design Engineer, you’ll own the “last mile” of cluster architecture - transforming high-level design specifications into efficient, real-world deployment blueprints for servers, storage, networking, and cabling. You’ll be responsible for customizing data center and rack-level designs based on specific cluster requirements - adapting layouts, power, and connectivity to optimize performance, scalability, and reliability. When real-world constraints like space, power, or supply chain limitations arise, you’ll make smart trade-offs to deliver practical, deployable solutions. This role combines hands-on problem solving with automation and tooling - you’ll also help design and build the frameworks that make each new deployment iteration faster, smarter, and more consistent across sites. It’s a great opportunity for someone early in their career who enjoys working at the intersection of hardware, software, and operations, and wants to shape the foundation of large-scale compute infrastructure. Responsibilities Translate cluster and rack-level design specifications into deployable blueprints for servers, storage, networking, and cabling. Customize rack-level designs to meet unique cluster requirements, ensuring power, thermal, and network connectivity are optimized for each deployment. Collaborate with operations team to validate and adapt designs based on site-specific constraints (e.g., power, cooling, space, logistics). Identify and implement automation and tooling to streamline BOM generation and design validation. Participate in data center deployment reviews, ensuring alignment between design intent and implementation. Support issue triage and root cause analysis for deployment-related or physical integration problems. Skills & Qualifications Bachelor’s or Master’s degree in Computer Engineering, Electrical Engineering, Computer Science, or a related field — or equivalent practical experience. 1–3 years of experience in infrastructure engineering, data center design, or systems deployment, creating rack elevations, bill of materials (BOMs), and port/cable maps. Familiarity with servers, networking, and storage hardware. Basic proficiency in scripting or automation (e.g., Python, PowerShell, or Bash). Strong analytical and problem-solving skills with attention to detail. Excellent communication and teamwork skills across multiple engineering disciplines. Why Join Cerebras People who are serious about software make their own hardware. At Cerebras we have built a breakthrough architecture that is unlocking new opportunities for the AI industry. With dozens of model releases and rapid growth, we’ve reached an inflection  point in our business. Members of our team tell us there are five main reasons they joined Cerebras: Build a breakthrough AI platform beyond the constraints of the GPU. Publish and open source their cutting-edge AI research. Work on one of the fastest AI supercomputers in the world. Enjoy job stability with startup vitality. Our simple, non-corporate work culture that respects individual beliefs. Read our blog: Five Reasons to Join Cerebras in 2025. Apply today and become part of the forefront of groundbreaking advancements in AI! Cerebras Systems is committed to creating an equal and diverse environment and is proud to be an equal opportunity employer. We celebrate different backgrounds, perspectives, and skills. We believe inclusive teams build better products and companies. We try every day to build a work environment that empowers people to do their best work through continuous learning, growth and support of those around them. This website or its third-party tools process personal data. For more details, click here to review our CCPA disclosure notice.",https://aijobs.ai/job/applied-data-center-design-engineer
Engineering Manager - AI Business Services (f/m/d),Contentful,"London,  England,  United Kingdom",Remote,Senior,,,,,"About the Opportunity We are looking for an Engineering Manager (f/m/d) to lead a new Business Services team, focused on building AI-enabled products for marketers . This team will play a key role in expanding Contentful’s impact by capturing adjacent spend and workflows, driving innovation at the intersection of content, data, and AI. Because this is a new group being formed, it represents a unique opportunity to act as an entrepreneur inside Contentful: shaping vision, culture, and execution from the ground up. What to expect? In this role you’ll get to work closely with senior stakeholders across the business to understand business strategy & goals, and work with internal teams and external partners to ensure our technical architecture, tech stack and development strategy are aligned to deliver impact against business goals. Lead and grow a high-performing, globally-distributed engineering team , ensuring a culture of collaboration, ownership, and continuous improvement. Partner with Product, Design, and cross-functional stakeholders to define the roadmap for AI-enabled marketing solutions. Build scalable, high-performance products that integrate AI capabilities into marketers’ daily workflows, with a focus on usability, automation, and business impact. Drive innovation and experimentation while ensuring secure, reliable, and performant systems. Mentor and develop engineers across levels , fostering technical excellence and leadership growth. Guide the team through solution design, coding, testing, deployment, and operations. Ensure alignment between technical execution and business objectives , with clear communication of progress and priorities. What you need to be successful We’re looking for an enthusiastic and entrepreneurial Engineering Manager (f/m/d) who thrives in building new teams and products. To succeed in this role, you should: 2+ years of experience leading development teams, with a track record of delivering complex, high-impact technical solutions. Be comfortable operating in ambiguous, fast-changing environments , balancing short-term impact with long-term strategy. Experience building or integrating AI-powered products (e.g., LLM-based systems, recommendation engines, personalization features), with a focus on delivering customer and business impact. Bring technical depth in modern web technologies and AI/ML-enabled applications, with enough hands-on experience to guide solutioning and challenge technical decisions. Excel at optimizing performance and scalability , with experience handling complex content structures and large datasets. Balance innovation with immediate impact , overseeing technical delivery while driving team capabilities and capacity. You’re eager to work with the latest technologies and products. Collaborate effectively across teams (Product, Design, Data, Engineering), aligning technical work with business goals. Have a strong mentoring track record, fostering a culture of continuous learning, technical excellence, and quality within a distributed team. Embrace continuous learning , staying up to date with industry trends and encouraging growth within your team. Bonus: Familiarity with martech ecosystems, marketing workflows, and integrations. Experience working in entrepreneurial or incubation environments, such as starting new teams or products from scratch. Knowledge of data privacy, compliance, and security best practices in SaaS and AI-enabled applications. What’s in it for you? Join an ambitious tech company reshaping the way people build digital experiences Full-time employees receive Stock Options for the opportunity to share in the success of our company Fertility and family building benefits, including a lifetime reimbursable wallet to support your growing family. We value Work-Life balance and You Time ! A generous amount of paid time off, including vacation days, sick days,  education days, compassion days for loss, and volunteer days Time off to care for and focus on your growing family Use your personal annual education budget to improve your skills and grow in your career Enjoy a full range of virtual and in-person events, including workshops, guest speakers, and fun team activities, supporting learning and networking exchange beyond the usual work duties An annual wellbeing stipend to care for your physical, financial, or emotional health A monthly communication phone/internet stipend and phone hardware upgrade reimbursement. New hire office equipment stipend for hybrid or distributed employees. Get the gear you need to work at your best. #LI-Remote #LI-KH1 Who are we? Contentful is a leading digital experience platform that helps modern businesses meet the growing demand for engaging, personalized content at scale. By blending composability with native AI capabilities, Contentful enables dynamic personalization, automated content delivery, and real-time experimentation, powering next-generation digital experiences across brands, regions, and channel",https://aijobs.ai/job/engineering-manager-ai-business-services-fmd-1
Senior Software Engineer - AI & .NET Platforms - boostCX,Banyan Software,"Toronto,  Ontario,  Canada",Hybrid,Senior,0.0,115000.0,57500.0,"Azure, JavaScript, AWS, Git, Angular, TensorFlow, PyTorch","Banyan Software provides the best permanent home for successful enterprise software companies, their employees, and customers. We are on a mission to acquire, build and grow great enterprise software businesses all over the world that have dominant positions in niche vertical markets. In recent years, Banyan was named the #1 fastest-growing private software company in the US on the Inc. 5000 and amongst the top 10 fastest-growing companies by the Deloitte Technology Fast 500. Founded in 2016 with a permanent capital base setup to preserve the legacy of founders, Banyan focuses on a buy and hold for life strategy for growing software companies that serve specialized vertical markets. Job Title: Senior .NET Developer Location: Burlington, Greater Toronto Area (Hybrid) Job Type: Full-Time Company: boostCX (A Banyan Software Portfolio Company) Salary Range: CAD 90,000-115,000 per annum About boostCX: boostCX is a customer experience technology provider focused on empowering organizations with intuitive, scalable tools that drive engagement, retention, and performance. As part of the Banyan Software portfolio, we operate with a long-term, sustainable approach, prioritizing customer success and product excellence. Position Overview: We are looking for a qualified developer to join our team to build, maintain, and evolve customer-facing and backend internal web applications using SQL, .NET, C#, and JavaScript. In addition to core development skills, this role requires experience with Artificial Intelligence - particularly building platform intelligence to digest and analyze large data sets, enabling smarter products and decision-making capabilities. Key Responsibilities: Collaborate with the product team on new system development and roadmap future features. Design, implement, and maintain AI-driven services that process and analyze structured and unstructured data at scale. Write well-designed, testable, efficient code using industry best practices. Improve, maintain, and scale existing applications and services. Integrate data from various back-end services, APIs, and databases. Develop intelligent reporting, recommendations, or insights features using AI/ML techniques. Create and maintain software and system documentation. Required Qualifications: A bachelor’s or master’s degree in software design, engineering, computer science, data science, or 4+ years of equivalent experience. Proficient in languages: C#, ASP.NET , MVC/Webforms/Services, JavaScript (jQuery, Angular a plus), T-SQL, Bootstrap, CSS. Experience in AI/ML frameworks and tools (such as TensorFlow, PyTorch, ML.NET , Azure Cognitive Services, or OpenAI APIs). Strong background in designing data pipelines, feature engineering, and working with large-scale datasets. Experience with data visualization and developing and delivering actionable insights from analytics. Familiarity with cloud platforms (Azure) for deploying AI-enabled solutions. Social integration experience is a plus (Facebook Graph API, GMB, etc.). 3+ years of professional software development experience. Analytical skills, attention to detail, and the ability to work effectively as part of a team. Nice to Have: Experience with cloud platforms (Azure, AWS). Familiarity with agile development methodologies. Git or similar version control systems. Why Join Us: Join a stable, growth-oriented business with a long-term mindset. Make a direct impact on revenue and company direction. Work with a collaborative, supportive, and values-driven team. Competitive base salary + uncapped commission + benefits. How to Apply: Please submit your resume, and if available, a portfolio or links to relevant projects you’ve worked on. Diversity, Equity, Inclusion & Equal Employment Opportunity at Banyan: Banyan affirms that inequality is detrimental to our Global Teams, associates, our Operating Companies, and the communities we serve. As a collective, our goal is to impact lasting change through our actions. Together, we unite for equality and equity. Banyan is committed to equal employment opportunities regardless of any protected characteristic, including race, color, genetic information, creed, national origin, religion, sex, affectional or sexual orientation, gender identity or expression, lawful alien status, ancestry, age, marital status, or protected veteran status and will not discriminate against anyone on the basis of a disability. We support an inclusive workplace where associates excel based on personal merit, qualifications, experience, ability, and job performance. Beware of Recruitment Scams We have been made aware of individuals fraudulently posing as members of our Talent Acquisition team and extending fake job offers. These scams may involve requests for personal information or payment for equipment. Protect yourself by following these steps: Verify that all communications from our recruiting team come from an @banyansoftware.com email address. Remember, employers will never request payment o",https://aijobs.ai/job/senior-software-engineer-ai-net-platforms-boostcx
"Staff Machine Learning Engineer, Data Collections AI & ML",PitchBook Data,"Seattle,  Washington,  United States",Remote,Senior,0.0,325000.0,162500.0,"Machine Learning, TensorFlow, PyTorch","At PitchBook, a Morningstar company, we are always looking forward. We continue to innovate, evolve, and invest in ourselves to bring out the best in everyone. We’re deeply collaborative and thrive on the excitement, energy, and fun that reverberates throughout the company. Our extensive learning programs and mentorship opportunities help us create a culture of curiosity that pushes us to always find new solutions and better ways of doing things. The combination of a rapidly evolving industry and our high ambitions means there’s going to be some ambiguity along the way, but we excel when we challenge ourselves. We’re willing to take risks, fail fast, and do it all over again in the pursuit of excellence. If you have a good attitude and are willing to roll up your sleeves to get things done, PitchBook is the place for you. About the Role: The Data Collection AI/ML team builds intelligent systems that scale and improve PitchBook’s data extraction, enrichment, and validation processes. The team applies advanced ML including classification, entity/relationship extraction, LLM-based parsing, OCR, and anomaly detection to ensure high accuracy, coverage, and timeliness of our proprietary datasets. The Staff MLE role is a force multiplier for the team, partnering with technical leadership to set best practices and design reusable ML architectures that support rapid innovation and operational excellence. As a Staff Machine Learning Engineer on the Data Collection AI/ML team, you will serve as the senior technical expert responsible for designing, architecting, and deploying advanced AI and machine learning systems that power PitchBook’s data collection, extraction, and enrichment workflows. You will play a pivotal role in elevating the technical bar of the organization by setting engineering standards, driving architectural decisions, and supporting teams to build scalable, production-grade ML systems. Your work will focus on automating and enhancing PitchBook’s ingestion and data quality pipelines across a wide variety of structured and unstructured sources, drawing from domain areas such as document understanding, OCR, natural language processing, entity resolution, multimodal modeling, retrieval systems, and LLM-driven extraction. You will collaborate closely with Engineering, Product, and Data Operations partners to translate business requirements into robust, high-impact AI solutions. This role is ideal for someone who thrives as a deeply technical individual contributor and wants to push the boundaries of document AI and data extraction technology, shape long-term architectural direction, and materially influence the future of data automation at PitchBook. In addition to driving product impact, this role offers an opportunity to shape PitchBook’s growing presence and technical reputation in the AI and ML space. We are looking for individuals who are active contributors to the broader AI community through peer-reviewed research, technical publications, or open-source initiatives. Candidates who have authored conference papers or patents and who are excited to explore the frontiers of generative AI, LLMs, and applied NLP will be well-positioned to help us both advance our internal capabilities and deepen trust with our customers through thought leadership Primary Job Responsibilities: Serve as the key technical leader shaping system design, ML architectures, model lifecycles, and scalable infrastructure for data extraction, document understanding, and structured data enrichment Architect reusable frameworks and services for LLM-powered extraction, entity recognition and resolution models, and multimodal document processing Partner with engineering leaders to ensure our systems meet the highest standards of reliability, performance, and cost efficiency Design and build state-of-the-art ML models using transformers, LLMs, generative models, graph-based approaches, and OCR/Document AI frameworks Identify opportunities to advance automation and accuracy across our ingestion stack, including entity linking, relationship inference, classification, and anomaly detection Translate emerging research into practical, production-ready capabilities Contribute to PitchBook’s growing technical reputation through experimentation, publication, or open-source work Work closely with Product, Engineering, and Data Operations to ensure AI systems integrate smoothly into human-in-the-loop workflows and downstream pipelines Provide technical expertise during prioritization discussions, roadmap planning, and long-term strategic design Elevate engineering excellence through code reviews, design reviews, and technical guidance for ML engineers and scientists Act as a multiplier by shaping best practices for experimentation, model evaluation, responsible AI, and scalable ML engineering Guide teams across the organization toward cohesive, reusable, and standards-aligned architectures Own the lifecycle of mission-critical ML systems from da",https://aijobs.ai/job/staff-machine-learning-engineer-data-collections-ai-ml
